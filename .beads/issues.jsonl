{"id":"bd-11y","title":"CLI & Interface (Deferred)","status":"open","priority":3,"issue_type":"epic","created_at":"2026-02-13T23:54:25.581112Z","created_by":"hsingh","updated_at":"2026-02-14T00:11:44.990925Z","source_repo":".","compaction_level":0,"original_size":0,"comments":[{"id":1,"issue_id":"bd-11y","author":"Harpreet Singh","text":"## Epic: CLI & Interface (Deferred)\n\nThe CLI wraps all pipeline functionality into a single `ggs` command with subcommands. This is deferred (P3) because the underlying modules work fine without a CLI during development. The CLI adds polish and usability but not analytical capability.\n\n### CLI design (PLAN.md Section 9)\n```\nggs corpus extract --config config/config.yaml\nggs corpus validate\nggs corpus cross-validate\nggs analysis lexical --config config/config.yaml\nggs analysis structural --config config/config.yaml\nggs analysis tags --config config/config.yaml\nggs pipeline run --phases 0,1,2,3\nggs lexicon lint\nggs bundle build\n```\n\n### Framework: Typer\nTyper provides automatic help generation, type-safe arguments, and rich console output — all aligned with our AGENTS.md requirement for \"stylish and colorful\" output using rich.\n\n### When to implement\nAfter all phases work end-to-end. The CLI is a convenience wrapper, not a prerequisite. During development, modules are invoked directly.\n\n### Children\n- bd-11y.1: CLI framework with Typer\n- bd-11y.2: Corpus subcommands (extract, validate, cross-validate)\n- bd-11y.3: Analysis subcommands (lexical, structural, tags)\n- bd-11y.4: Pipeline orchestrator (ggs pipeline run)\n","created_at":"2026-02-14T00:11:44Z"}]}
{"id":"bd-11y.1","title":"Implement CLI framework with Typer (cli.py)","status":"open","priority":3,"issue_type":"task","created_at":"2026-02-13T23:55:36.793941Z","created_by":"hsingh","updated_at":"2026-02-14T00:12:14.572049Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli"],"dependencies":[{"issue_id":"bd-11y.1","depends_on_id":"bd-11y","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-11y.1","depends_on_id":"bd-298.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":2,"issue_id":"bd-11y.1","author":"Harpreet Singh","text":"## Task: Implement CLI framework with Typer (cli.py)\n\nSet up the Typer application with common options and the subcommand structure.\n\n### Common options (all subcommands accept)\n- `--config <path>` (default: config/config.yaml)\n- `--output <dir>`\n- `--force` (bypass cache)\n- `--dry-run` (show what would be done, don't do it)\n- `--verbose / -v` (increase log level)\n- `--workers N` (parallel workers, default: cpu_count)\n\n### Subcommand groups\n- `ggs corpus ...` — Phase 0 operations\n- `ggs analysis ...` — Phase 1-3 operations\n- `ggs pipeline ...` — Multi-phase orchestration\n- `ggs lexicon ...` — Lexicon tools\n- `ggs bundle ...` — Web bundle operations\n\n### Rich integration\nAll console output uses rich:\n- Progress bars for long-running operations (scraping, matching)\n- Tables for summary statistics\n- Colored status indicators (green=pass, red=fail, yellow=warning)\n- Panel output for run manifests\n\n### Depends on\nbd-298.1 (package structure — cli.py lives in src/ggs/)\n","created_at":"2026-02-14T00:12:14Z"}]}
{"id":"bd-11y.2","title":"Implement corpus subcommands (extract, validate, cross-validate)","status":"open","priority":3,"issue_type":"task","created_at":"2026-02-13T23:55:37.769135Z","created_by":"hsingh","updated_at":"2026-02-14T00:12:14.615393Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli"],"dependencies":[{"issue_id":"bd-11y.2","depends_on_id":"bd-11y","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-11y.2","depends_on_id":"bd-11y.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-11y.2","depends_on_id":"bd-15c.8","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":3,"issue_id":"bd-11y.2","author":"Harpreet Singh","text":"## Task: Implement corpus subcommands (extract, validate, cross-validate)\n\nWire Phase 0 modules into CLI subcommands under `ggs corpus`.\n\n### Subcommands\n- `ggs corpus extract` — Run scraper + parser + normalizer + tokenizer → ggs_lines.jsonl\n- `ggs corpus validate` — Run validator on existing corpus\n- `ggs corpus cross-validate` — Run cross-validation against secondary source\n\n### Depends on\nbd-11y.1 (CLI framework)\nbd-15c.8 (Phase 0 integration — the underlying modules)\n","created_at":"2026-02-14T00:12:14Z"}]}
{"id":"bd-11y.3","title":"Implement analysis subcommands (lexical, structural, tags)","status":"open","priority":3,"issue_type":"task","created_at":"2026-02-13T23:55:38.599935Z","created_by":"hsingh","updated_at":"2026-02-14T00:12:14.657751Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli"],"dependencies":[{"issue_id":"bd-11y.3","depends_on_id":"bd-11y","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-11y.3","depends_on_id":"bd-11y.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-11y.3","depends_on_id":"bd-2zi.3","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-11y.3","depends_on_id":"bd-4i2.5","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-11y.3","depends_on_id":"bd-9qw.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":4,"issue_id":"bd-11y.3","author":"Harpreet Singh","text":"## Task: Implement analysis subcommands (lexical, structural, tags)\n\nWire Phase 1-3 modules into CLI subcommands under `ggs analysis`.\n\n### Subcommands\n- `ggs analysis lexical` — Run Phase 1 (matching engine → matches.jsonl + reports)\n- `ggs analysis structural` — Run Phase 2 (features + co-occurrence → features.jsonl)\n- `ggs analysis tags` — Run Phase 3 (tagging → tags.jsonl + distribution reports)\n\nEach subcommand:\n1. Validates that required input artifacts exist\n2. Checks cache for skip-if-unchanged\n3. Runs the phase\n4. Generates run_manifest.json\n5. Reports summary to console\n\n### Depends on\nbd-11y.1 (CLI framework)\nbd-4i2.5 (matching), bd-9qw.1 (features), bd-2zi.3 (tagger) — the underlying modules\n","created_at":"2026-02-14T00:12:14Z"}]}
{"id":"bd-11y.4","title":"Implement pipeline orchestrator command (ggs pipeline run)","status":"open","priority":3,"issue_type":"task","created_at":"2026-02-13T23:55:39.653311Z","created_by":"hsingh","updated_at":"2026-02-14T00:12:14.699769Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli"],"dependencies":[{"issue_id":"bd-11y.4","depends_on_id":"bd-11y","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-11y.4","depends_on_id":"bd-11y.2","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-11y.4","depends_on_id":"bd-11y.3","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":5,"issue_id":"bd-11y.4","author":"Harpreet Singh","text":"## Task: Implement pipeline orchestrator command (ggs pipeline run)\n\nThe orchestrator runs multiple phases in sequence with a single command.\n\n### Usage\n```bash\nggs pipeline run --phases 0,1,2,3         # Run all phases\nggs pipeline run --phases 1,2              # Run just lexical + structural\nggs pipeline run --phases 0,1,2,3 --force  # Re-run everything, ignore cache\n```\n\n### Behavior\n1. Parse --phases argument into ordered list\n2. For each phase in order:\n   a. Validate input artifacts exist (produced by previous phase)\n   b. Check cache (skip if unchanged, unless --force)\n   c. Run phase\n   d. Validate output artifacts\n   e. Report timing and summary\n3. If any phase fails, abort pipeline (don't run subsequent phases)\n4. At end: summary table showing each phase's status, timing, record counts\n\n### Phase input validation\nBefore Phase 1 starts, verify ggs_lines.jsonl exists. Before Phase 2 starts, verify matches.jsonl exists. Etc. If a required input is missing, print an actionable error: \"Phase 1 requires data/corpus/ggs_lines.jsonl. Run: ggs corpus extract\"\n\n### Depends on\nbd-11y.2 (corpus subcommands), bd-11y.3 (analysis subcommands) — wraps all of them\n","created_at":"2026-02-14T00:12:14Z"}]}
{"id":"bd-15c","title":"Phase 0: Canonical Corpus Extraction","status":"closed","priority":0,"issue_type":"epic","created_at":"2026-02-13T23:54:21.389064Z","created_by":"hsingh","updated_at":"2026-02-14T04:01:33.468312Z","closed_at":"2026-02-14T04:01:33.468297Z","close_reason":"Phase 0 corpus extraction complete - 60,629 lines from all 1430 angs","source_repo":".","compaction_level":0,"original_size":0,"comments":[{"id":6,"issue_id":"bd-15c","author":"Harpreet Singh","text":"## Epic: Phase 0 — Canonical Corpus Extraction\n\nThis is the most critical epic. Phase 0 produces the canonical corpus that ALL downstream analysis depends on. If the corpus is wrong, everything built on top of it is wrong. This is why it's P0 priority.\n\n### What Phase 0 does\n1. Scrapes all 1430 angs from SriGranth.org (primary source)\n2. Parses HTML into structured records with Gurmukhi text + metadata\n3. Normalizes Unicode Gurmukhi through a 7-step pipeline\n4. Tokenizes normalized text with character-offset spans\n5. Validates corpus integrity (unique IDs, valid normalization, shabad consistency)\n6. Optionally cross-validates against secondary sources\n\n### Key output: ggs_lines.jsonl\n~60,000 lines, each a JSON record with:\n- gurmukhi_raw (preserved original)\n- gurmukhi (normalized canonical form)\n- tokens + token_spans\n- Structural metadata (author, raga, shabad_uid, rahao, pauri)\n- Stable identifiers (line_uid = hash(ang + gurmukhi))\n\n### Critical design decisions\n- Normalization changes invalidate line_uids (intentional — normalization fix = corpus change)\n- shabad_uid is position-based, not content-based (avoids circular dependency)\n- Parser and normalizer are decoupled: parser extracts raw text, normalizer processes it\n- This means parser and normalizer can be developed in parallel\n\n### Risks\n- SriGranth.org could go down or block scraping → mitigated by committed snapshots\n- Gurmukhi encoding inconsistencies across pages → mitigated by normalization pipeline\n- Shabad boundaries may be ambiguous in HTML → mitigated by validation warnings\n\n### Children (execution order)\n1. bd-15c.1: Normalization pipeline (can start after scaffold)\n2. bd-15c.3: Parser (can start after scaffold, PARALLEL with normalizer)\n3. bd-15c.2: Tokenizer (needs normalizer done first)\n4. bd-15c.4: Structural metadata (needs parser)\n5. bd-15c.5: Scraper (needs parser)\n6. bd-15c.6: Validator (needs normalizer + tokenizer)\n7. bd-15c.7: Cross-validation (needs parser + validator)\n8. bd-15c.8: Integration (needs everything above)\n","created_at":"2026-02-14T00:11:44Z"}]}
{"id":"bd-15c.1","title":"Implement normalization pipeline (normalize.py)","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-13T23:54:38.739423Z","created_by":"hsingh","updated_at":"2026-02-14T01:05:32.352626Z","closed_at":"2026-02-14T01:05:32.352612Z","close_reason":"Implemented 7-step normalization pipeline: NFC, zero-width strip, nukta policy, nasal normalization, vishram handling, halant canonicalization, whitespace normalization. All steps are pure functions, pipeline is idempotent, config-driven via NormalizationConfig. Includes DUAL mode for nukta sensitivity analysis.","source_repo":".","compaction_level":0,"original_size":0,"labels":["corpus","phase0"],"dependencies":[{"issue_id":"bd-15c.1","depends_on_id":"bd-15c","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-15c.1","depends_on_id":"bd-298.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":7,"issue_id":"bd-15c.1","author":"Harpreet Singh","text":"## Task: Implement normalization pipeline (normalize.py)\n\nThis is THE most important single module in the project. The normalization pipeline transforms raw scraped Gurmukhi into the canonical form used by every downstream analysis step. Correctness here is paramount.\n\n### The 7-step pipeline (PLAN.md Section 3.4)\n\n1. **Unicode NFC** — Canonical decomposition followed by canonical composition. This is the standard first step for any Unicode text processing.\n\n2. **Zero-width character stripping** — Remove ZWJ (U+200D) and ZWNJ (U+200C). These are rendering hints that don't affect linguistic content. Some Gurmukhi fonts insert them; we strip for consistency.\n\n3. **Nukta policy** (configurable: PRESERVE | STRIP | DUAL)\n   - Nukta (਼) distinguishes borrowed sounds: ਖ਼ vs ਖ, ਗ਼ vs ਗ, etc.\n   - PRESERVE (default): keep nukta variants as distinct tokens. This matters for register analysis since nukta forms are markers of Perso-Arabic register.\n   - STRIP: collapse all nukta variants. Use when register analysis isn't needed.\n   - DUAL: produce both, enabling sensitivity analysis.\n\n4. **Nasal marker normalization** (configurable: CANONICAL_TIPPI | CANONICAL_BINDI | PRESERVE)\n   - Tippi (ੰ) and Bindi (ਂ) represent the same nasal sound but sources use them inconsistently.\n   - Without normalization, \"ਸੰਤ\" and \"ਸਂਤ\" would be two different tokens for the same word.\n   - Default CANONICAL_TIPPI normalizes all to Tippi.\n\n5. **Vishram marker handling** (STRIP | PRESERVE_SEPARATE)\n   - Vishram markers (pause markers) are performative notation, not linguistic content.\n   - STRIP (default): remove them entirely for analysis.\n\n6. **Halant/conjunct canonicalization** (DECOMPOSE | PRESERVE)\n   - Different fonts/input methods produce different byte sequences for the same conjunct consonant.\n   - DECOMPOSE ensures: same sound → same bytes.\n\n7. **Whitespace normalization** — Collapse runs of whitespace, trim leading/trailing.\n\n### Implementation requirements\n- Each step is a pure function: `str → str`\n- Pipeline is composed as: `step7(step6(step5(step4(step3(step2(step1(text)))))))`\n- Each step must be independently testable\n- The full pipeline must be idempotent: `normalize(normalize(x)) == normalize(x)`\n- Pipeline version string recorded in run_manifest.json\n\n### Config integration\nReads policy settings from config.yaml's `normalization:` section.\n\n### Why P0 priority\nThis is on the critical path. The tokenizer depends on it. The validator depends on it. Line UIDs are computed from normalized text. If this is wrong, everything downstream is wrong.\n\n### Depends on\nbd-298.1 (package structure)\n","created_at":"2026-02-14T00:11:55Z"}]}
{"id":"bd-15c.2","title":"Implement tokenizer with token_spans (tokenize.py)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:54:39.635565Z","created_by":"hsingh","updated_at":"2026-02-14T01:18:31.672726Z","closed_at":"2026-02-14T01:18:31.672714Z","close_reason":"Implemented tokenizer with token_spans: 4-step algorithm (extract structural markers, whitespace split, strip boundary punct, filter empty). TokenizeResult dataclass with tokens/token_spans/structural_markers. Handles rahao, dandas, Gurmukhi numerals as structural markers. Span positions map back to original gurmukhi string.","source_repo":".","compaction_level":0,"original_size":0,"labels":["corpus","phase0"],"dependencies":[{"issue_id":"bd-15c.2","depends_on_id":"bd-15c","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-15c.2","depends_on_id":"bd-15c.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":8,"issue_id":"bd-15c.2","author":"Harpreet Singh","text":"## Task: Implement tokenizer with token_spans (tokenize.py)\n\nThe tokenizer splits normalized Gurmukhi text into tokens and tracks character offsets. This is critical for concordance highlighting and match span validation.\n\n### Algorithm (PLAN.md Section 3.5)\n\nInput: `gurmukhi` (post-normalization string)\n\n1. **Extract structural markers** — Remove ਰਹਾਉ, Gurmukhi numerals (੧੨੩...), double-danda (॥), etc. Store in `meta.structural_markers`.\n2. **Split on whitespace** — Gurmukhi is whitespace-delimited (unlike CJK).\n3. **Strip residual punctuation** from token boundaries.\n4. **Filter empty tokens**.\n\nOutput: `tokens` list + `token_spans` list + `structural_markers`\n\n### token_spans: the key innovation\n`token_spans` is a parallel array to `tokens`. Each entry is `[start, end]` — character offsets into the `gurmukhi` string.\n\nExample:\n```\ngurmukhi: \"ਸਤਿ ਨਾਮੁ ਕਰਤਾ\"\ntokens:      [\"ਸਤਿ\",  \"ਨਾਮੁ\",  \"ਕਰਤਾ\"]\ntoken_spans: [[0,3],   [4,8],    [9,14]]\n```\n\n### Why token_spans matter\n1. **Match → highlight mapping**: When the matcher finds entity \"ਨਾਮੁ\" at span [4,8], the webapp can highlight exactly those characters.\n2. **Validation**: Every match span must align to token boundaries. If a match span doesn't correspond to any token_span, something is wrong.\n3. **Token-level analysis**: Density scores divide by token count. Token spans let us verify that token count is correct.\n\n### Edge cases to handle\n- Empty lines (0 tokens — valid but flagged by validator)\n- Lines that are entirely structural markers (e.g., just \"॥੧॥ ਰਹਾਉ ॥\")\n- Lines with >200 tokens (flag as WARNING, likely a parsing error)\n- Punctuation-only tokens after stripping (should be filtered)\n\n### Depends on\nbd-15c.1 (normalization pipeline — tokenizer operates on normalized text)\n","created_at":"2026-02-14T00:11:56Z"}]}
{"id":"bd-15c.3","title":"Implement SriGranth HTML parser (parse_srigranth.py)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:54:40.695580Z","created_by":"hsingh","updated_at":"2026-02-14T01:11:13.826990Z","closed_at":"2026-02-14T01:11:13.826977Z","close_reason":"Implemented SriGranth HTML parser: parse_ang() extracts Gurmukhi lines via class-based and Unicode-ratio fallback strategies, detects structural metadata (author/Mahalla, raga, rahao, pauri, shabad boundaries), produces canonical records via to_canonical_records(). Includes compute_line_uid() and compute_shabad_uid() per PLAN.md specs.","source_repo":".","compaction_level":0,"original_size":0,"labels":["corpus","phase0"],"dependencies":[{"issue_id":"bd-15c.3","depends_on_id":"bd-15c","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-15c.3","depends_on_id":"bd-298.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":9,"issue_id":"bd-15c.3","author":"Harpreet Singh","text":"## Task: Implement SriGranth HTML parser (parse_srigranth.py)\n\nThe parser extracts structured Gurmukhi text from SriGranth.org HTML pages. This is the primary data ingestion path for the entire project.\n\n### Source URL pattern\n`https://www.srigranth.org/servlet/gurbani.gurbani?Action=Page&Param=<ANG>`\n\n### What the parser must extract per line\n- `gurmukhi_raw`: exact Unicode text from the HTML (before any normalization)\n- `ang`: page number (1-1430)\n- `line_id`: human-readable sequential ID (e.g., \"433:07\")\n- `meta.author`: from Mahalla notation or author headers\n- `meta.raga`: from raga section headers\n- `meta.shabad_id`: sequential within raga section\n- `meta.rahao`: boolean (line contains ਰਹਾਉ)\n- `meta.pauri`: stanza number if present\n- `source_ang_url`: the URL this was scraped from\n\n### Implementation approach\n- Use BeautifulSoup + lxml for HTML parsing\n- Identify the Gurmukhi text table/div structure in SriGranth HTML\n- Extract line-by-line, preserving original Unicode exactly\n- Parse structural headers (raga changes, author changes) as they appear in page flow\n- Handle edge cases: pages with mixed content, continuation of shabads across page boundaries\n\n### Parser abstraction (Section 3.1.1)\nThis parser produces the canonical record format (Section 3.3). Other parsers (parse_igurbani.py, etc.) would produce the same format. Parser selection is config-driven. For MVP, only the SriGranth parser is needed.\n\n### Important: parser does NOT normalize\nThe parser outputs `gurmukhi_raw` only. Normalization is a separate step (bd-15c.1). This separation means:\n- Parser bugs don't affect normalization\n- Normalization bugs don't require re-scraping\n- We can diff raw vs. normalized to audit the normalization pipeline\n\n### Depends on\nbd-298.1 (package structure — needs the module to live somewhere)\n\n### Note: can be developed in PARALLEL with normalizer (bd-15c.1)\nThese two tasks have no dependency on each other. The parser extracts raw text; the normalizer processes it. They meet at the integration step (bd-15c.8).\n","created_at":"2026-02-14T00:11:56Z"}]}
{"id":"bd-15c.4","title":"Implement structural metadata extraction (author, raga, shabad, rahao)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:54:41.810248Z","created_by":"hsingh","updated_at":"2026-02-14T01:15:06.250844Z","closed_at":"2026-02-14T01:15:06.250830Z","close_reason":"Structural metadata extraction (author, raga, shabad, rahao, pauri) was implemented as part of parse_srigranth.py (bd-15c.3). The parser already detects Mahalla notation for author, raga headers, rahao markers, pauri numerals, and generates shabad_id boundaries.","source_repo":".","compaction_level":0,"original_size":0,"labels":["corpus","phase0"],"dependencies":[{"issue_id":"bd-15c.4","depends_on_id":"bd-15c","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-15c.4","depends_on_id":"bd-15c.3","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":10,"issue_id":"bd-15c.4","author":"Harpreet Singh","text":"## Task: Implement structural metadata extraction (author, raga, shabad, rahao)\n\nThis task enriches each parsed line with structural metadata that is essential for conditioned analysis (e.g., \"entity frequency by author\" or \"register density by raga\").\n\n### Metadata fields (PLAN.md Section 3.1.2)\n\n**author**: Identified from Mahalla notation (ਮਹਲਾ ੧, ਮ: ੧, etc.) or explicit author headers.\n- Canonical IDs: M1 (Guru Nanak), M2, M3, M4, M5, M9, KABIR, FARID, NAMDEV, RAVIDAS, etc.\n- Unmapped authors stored as raw text with validation warning.\n\n**raga**: From raga headers in source HTML.\n- Validated against config/ragas.yaml canonical list.\n- Raga assignment persists until the next raga header appears.\n\n**shabad boundaries**: The fundamental compositional unit in the GGS.\n- On SriGranth: identified by shabad number annotations and visual separators in HTML.\n- Parser assigns sequential shabad_id per raga section (e.g., ASA-001).\n- shabad_uid = hash(ang of first line + line_id of first line) — position-based, NOT content-based.\n- If boundary detection fails: entire ang flagged with SHABAD_BOUNDARY_AMBIGUOUS.\n\n**pauri / stanza numbering**: From Gurmukhi numeral markers (੧, ੨, ...).\n- null if not present (many compositions don't have pauri numbers).\n\n**rahao detection**: Boolean flag when line contains ਰਹਾਉ (or variant spellings).\n- Set during parsing, before tokenization.\n- The ਰਹਾਉ token itself is later extracted to structural_markers by the tokenizer.\n\n### Why shabad_uid is position-based\nPLAN.md Section 3.3 explains: if shabad_uid were content-hash(all member lines), then a normalization fix to one line would change the shabad_uid of every sibling line. Position-based identity avoids this cascade because the structural layout of the GGS is canonically fixed.\n\n### Depends on\nbd-15c.3 (parser — metadata extraction is done within/alongside parsing)\n","created_at":"2026-02-14T00:11:56Z"}]}
{"id":"bd-15c.5","title":"Implement scraper with protocol compliance (scrape.py)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:54:42.630026Z","created_by":"hsingh","updated_at":"2026-02-14T01:24:25.373158Z","closed_at":"2026-02-14T01:24:25.373145Z","close_reason":"Implemented scraper with rate-limiting and protocol compliance. Features: 500-1500ms jitter, exponential backoff (max 5 retries), resumable via scrape_state.json, User-Agent identification, hard stop on repeated 403/429. Rich progress bar. ScrapeConfig, ScrapeState, fetch_ang(), scrape_corpus().","source_repo":".","compaction_level":0,"original_size":0,"labels":["corpus","phase0"],"dependencies":[{"issue_id":"bd-15c.5","depends_on_id":"bd-15c","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-15c.5","depends_on_id":"bd-15c.3","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":11,"issue_id":"bd-15c.5","author":"Harpreet Singh","text":"## Task: Implement scraper with protocol compliance (scrape.py)\n\nThe scraper fetches HTML pages from SriGranth.org for all 1430 angs. It must be respectful, resilient, and resumable.\n\n### Scraping protocol (PLAN.md Section 3.2)\n\n- **Rate limiting**: 500-1500ms random jitter between requests. This is non-negotiable — we are guests on their server.\n- **Retry strategy**: Exponential backoff (2s, 4s, 8s, 16s, 32s max) with max_retries=5.\n- **Resumable**: Writes `scrape_state.json` tracking which angs have been fetched. If interrupted, resume from where we left off.\n- **User-Agent**: `ggs-text-analysis/<version>` — transparent about what we are.\n- **Respect robots.txt/terms**: Check before first request.\n- **Hard stop on 403/429**: If we get repeated forbidden/rate-limit responses, stop immediately. Do not hammer the server.\n\n### Failure classification\nEach failure is categorized for targeted retry or investigation:\n- FETCH_HTTP_ERROR: non-200 response\n- FETCH_TIMEOUT: request timed out\n- FETCH_BLOCKED: 403/429 received\n- PARSE_SELECTOR_FAIL: HTML structure unexpected\n- PARSE_HEURISTIC_FAIL: parser couldn't extract expected data\n- OUTPUT_WRITE_FAIL: disk write failed\n\nFailures logged to `data/raw_html/failures.jsonl`.\n\n### Output\n- `data/raw_html/<ang>.html` — one file per ang\n- `data/raw_html/failures.jsonl` — failure log\n- `scrape_state.json` — resumable state\n\n### Implementation notes\n- Use httpx for HTTP (async-capable, modern)\n- The scraper calls the parser (bd-15c.3) to validate that fetched HTML is parseable before marking an ang as complete\n- If an ang's HTML changes on re-scrape, log a warning (corpus drift detection)\n\n### Ethics\nWe are building an analytical tool for a sacred text. We must treat source sites with respect. The rate limiting and user-agent transparency are not just technical requirements — they reflect the project's values.\n\n### Depends on\nbd-15c.3 (parser — scraper validates HTML is parseable)\n","created_at":"2026-02-14T00:11:56Z"}]}
{"id":"bd-15c.6","title":"Implement corpus validator (validate.py)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:54:43.346160Z","created_by":"hsingh","updated_at":"2026-02-14T01:21:00.675256Z","closed_at":"2026-02-14T01:21:00.675244Z","close_reason":"Implemented corpus validator: 10 checks (unique line_uid, non-empty gurmukhi, normalization idempotency, provenance fields, schema version, token count sanity, character repertoire, token_spans alignment). ValidationReport with pass/fail/warning counts and JSON export.","source_repo":".","compaction_level":0,"original_size":0,"labels":["corpus","phase0"],"dependencies":[{"issue_id":"bd-15c.6","depends_on_id":"bd-15c","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-15c.6","depends_on_id":"bd-15c.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-15c.6","depends_on_id":"bd-15c.2","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":12,"issue_id":"bd-15c.6","author":"Harpreet Singh","text":"## Task: Implement corpus validator (validate.py)\n\nThe validator is the quality gate between Phase 0 and all downstream analysis. If validation fails, the pipeline aborts. This prevents bad data from silently propagating.\n\n### Validation checks (PLAN.md Section 3.6)\n\n1. **Unique line_uid** — No two lines may share a line_uid. Duplicate = FATAL.\n2. **Non-empty gurmukhi** — Every line must have normalized text. Empty = ERROR (skip record).\n3. **Normalization idempotency** — Apply normalize() to each gurmukhi field. If output differs from stored value, normalization was not properly applied. FATAL.\n4. **Provenance fields present** — schema_version must exist on every record.\n5. **Schema version supported** — Validator must know how to handle the schema version. Unknown version = FATAL.\n6. **Pipeline version match** — Normalization pipeline version in corpus must match current code's version. Mismatch = WARNING (may indicate stale corpus).\n7. **Token count sanity** — Flag lines with 0 tokens (WARNING) or >200 tokens (WARNING, likely parse error).\n8. **Character repertoire** — Flag non-Gurmukhi Unicode characters outside the expected set (WARNING). The GGS is Gurmukhi text; unexpected characters suggest parsing artifacts.\n9. **Shabad integrity** — All lines in a shabad must be contiguous (no interleaving). shabad_uid must be consistent across all lines in the same shabad.\n10. **token_spans alignment** — Each span must fall within gurmukhi string length. No gaps between consecutive spans (complete coverage). No overlapping spans.\n\n### Output\n`data/corpus/validation_report.json` containing:\n- Total lines validated\n- Pass/fail counts per check\n- List of warnings with line_uids\n- List of errors with line_uids and error details\n- Overall verdict: PASS or FAIL\n\n### Error model integration\nUses the pipeline error model (bd-tun.1) for FATAL/ERROR/WARNING classification.\n\n### Depends on\nbd-15c.1 (normalization — for idempotency check)\nbd-15c.2 (tokenizer — for token_spans validation)\n","created_at":"2026-02-14T00:11:56Z"}]}
{"id":"bd-15c.7","title":"Implement cross-validation framework","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-13T23:54:44.089472Z","created_by":"hsingh","updated_at":"2026-02-14T03:23:01.995429Z","closed_at":"2026-02-14T03:23:01.995417Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["corpus","phase0"],"dependencies":[{"issue_id":"bd-15c.7","depends_on_id":"bd-15c","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-15c.7","depends_on_id":"bd-15c.3","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-15c.7","depends_on_id":"bd-15c.6","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":13,"issue_id":"bd-15c.7","author":"Harpreet Singh","text":"## Task: Implement cross-validation framework\n\nCross-validation compares our primary corpus (from SriGranth) against secondary sources to catch systematic errors. This is a quality assurance measure, not a primary data path.\n\n### Strategy (PLAN.md Section 3.1)\n\n1. Sample N angs (default 50) from a secondary source (e.g., GurbaniNow API — JSON, no scraping needed)\n2. For each sampled ang, parse lines from the secondary source using its own parser\n3. Normalize both primary and secondary text using the same normalization pipeline\n4. Compare line-by-line (after normalization)\n5. Log discrepancies to `data/corpus/cross_validation.jsonl`\n\n### Discrepancy handling\n- Discrepancies are WARNINGs, not errors\n- Sources legitimately differ in: whitespace, nukta usage, vishram markers, minor spelling variants\n- The report should classify discrepancies by type (whitespace-only, nukta-only, substantive)\n- Substantive discrepancies (different words entirely) warrant manual review\n\n### Why this matters\nA single-source corpus is fragile. If SriGranth has a systematic encoding issue on certain pages, we'd propagate it unknowingly. Cross-validation catches:\n- Pages where the HTML structure changed (parser extracted wrong content)\n- Encoding issues specific to one source\n- Missing lines or extra lines\n\n### Secondary source: GurbaniNow API\nThis is the easiest secondary source because it returns JSON (no HTML parsing needed). The API provides shabad-level data with clean Gurmukhi text. We can sample by ang range and compare.\n\n### Priority: P2\nThis is important for confidence but not blocking. The primary corpus can be used without cross-validation. This is an enhancement to quality assurance.\n\n### Depends on\nbd-15c.3 (parser — need parser infrastructure)\nbd-15c.6 (validator — cross-validation is a form of validation)\n","created_at":"2026-02-14T00:11:56Z"}]}
{"id":"bd-15c.8","title":"Phase 0 end-to-end integration and smoke test","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:54:45.240755Z","created_by":"hsingh","updated_at":"2026-02-14T01:30:30.949458Z","closed_at":"2026-02-14T01:30:30.949445Z","close_reason":"Phase 0 end-to-end integration complete. Created pipeline.py wiring parse->normalize->tokenize->validate->output. run_phase0() produces ggs_lines.jsonl + run_manifest.json + validation_report.json. Fixed compute_line_uid to include line_id for refrain disambiguation. 26 integration tests passing (115 total). All fixture angs (1-5) validate as PASS.","source_repo":".","compaction_level":0,"original_size":0,"labels":["integration","phase0"],"dependencies":[{"issue_id":"bd-15c.8","depends_on_id":"bd-15c","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-15c.8","depends_on_id":"bd-15c.2","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-15c.8","depends_on_id":"bd-15c.4","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-15c.8","depends_on_id":"bd-15c.5","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-15c.8","depends_on_id":"bd-15c.6","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":14,"issue_id":"bd-15c.8","author":"Harpreet Singh","text":"## Task: Phase 0 end-to-end integration and smoke test\n\nThis task brings together all Phase 0 components into a working pipeline: scrape → parse → normalize → tokenize → validate → output.\n\n### What \"integration\" means here\n\n1. Wire the components together:\n   - Scraper fetches HTML → Parser extracts gurmukhi_raw + metadata\n   - Normalizer processes gurmukhi_raw → gurmukhi\n   - Tokenizer processes gurmukhi → tokens + token_spans\n   - Compose full canonical record (Section 3.3)\n   - Write to ggs_lines.jsonl\n   - Generate manifest.json with provenance\n\n2. Run validator on output → produce validation_report.json\n\n3. Smoke test on fixture data (Ang 1-5):\n   - Use pre-saved HTML fixtures (not live scraping)\n   - Verify output matches expected canonical records\n   - This becomes the regression baseline\n\n### manifest.json generation\nPer PLAN.md Section 3.3, the manifest records per-ang source details:\n- url, retrieved_at, sha256 of raw HTML, parser_version\n- Keyed by ang number\n- Also records: pipeline versions, total line count, schema_version\n\n### Pipeline data flow verification\nAfter this task, we should be able to:\n```\n# From fixtures (no network)\npython -m ggs.corpus ... --input tests/fixtures/ --output /tmp/test_corpus/\n# Verify: /tmp/test_corpus/ggs_lines.jsonl exists and validates\n```\n\n### This is the Phase 0 \"done\" milestone\nWhen this task is complete, Phase 0 is functionally complete. The corpus is ready for Phase 1 consumption.\n\n### Depends on\nbd-15c.2 (tokenizer), bd-15c.4 (structural metadata), bd-15c.5 (scraper), bd-15c.6 (validator)\n— transitively covers bd-15c.1 (normalizer) and bd-15c.3 (parser)\n","created_at":"2026-02-14T00:11:56Z"}]}
{"id":"bd-298","title":"Project Scaffold & Infrastructure","status":"closed","priority":1,"issue_type":"epic","created_at":"2026-02-13T23:54:20.875884Z","created_by":"hsingh","updated_at":"2026-02-14T04:01:33.437286Z","closed_at":"2026-02-14T04:01:33.437273Z","close_reason":"All scaffold subtasks complete","source_repo":".","compaction_level":0,"original_size":0,"comments":[{"id":15,"issue_id":"bd-298","author":"Harpreet Singh","text":"## Epic: Project Scaffold & Infrastructure\n\nThis is the foundational epic. Every other epic in the project depends on the artifacts produced here. Nothing can begin until we have a working Python package with the right dependency set, configuration schema, and directory structure.\n\n### Why this matters\nThe project uses a src-layout Python package (`src/ggs/`) with subpackages for corpus, analysis, lexicon, and output. Getting this right from day one prevents painful restructuring later. The pyproject.toml must declare all dependencies (including dev deps like hypothesis, ruff, ty) and the package must be installable via `uv sync`.\n\n### Key decisions baked in\n- Python 3.14 only (per AGENTS.md)\n- uv for dependency management (never pip)\n- src-layout prevents accidental relative imports\n- rich for all console output\n- All config is YAML-driven (config.yaml, ragas.yaml, _schema.yaml)\n\n### Children\n- bd-298.1: pyproject.toml + package structure (THE critical path root)\n- bd-298.2: Configuration files\n- bd-298.3: Lexicon schema definition\n- bd-298.4: Data directory structure\n\n### Completion criteria\n`uv sync` succeeds, `python -c \"import ggs\"` works, all config files parse without error, data directories exist with appropriate .gitignore rules.\n","created_at":"2026-02-14T00:11:44Z"}]}
{"id":"bd-298.1","title":"Create pyproject.toml and Python package structure","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:54:33.190994Z","created_by":"hsingh","updated_at":"2026-02-14T01:02:10.580339Z","closed_at":"2026-02-14T01:02:10.580326Z","close_reason":"Scaffold complete: pyproject.toml, src/ggs/ package with all subpackages, tests/conftest.py, .gitignore. All imports verified, ruff clean.","source_repo":".","compaction_level":0,"original_size":0,"labels":["scaffold"],"dependencies":[{"issue_id":"bd-298.1","depends_on_id":"bd-298","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":16,"issue_id":"bd-298.1","author":"Harpreet Singh","text":"## Task: Create pyproject.toml and Python package structure\n\nThis is THE critical-path root of the entire project. Every single other task depends on this, directly or transitively. It must be done first and done right.\n\n### What to create\n\n1. `pyproject.toml` with:\n   - Project metadata (name=ggs, version=0.1.0, python>=3.14)\n   - Dependencies: pyyaml, rich, typer, ahocorasick-cffi (or pyahocorasick), beautifulsoup4, lxml, httpx (async HTTP client)\n   - Dev dependencies: pytest, hypothesis, ruff, coverage\n   - Build system: hatchling or setuptools with src-layout\n   - Tool configs: [tool.ruff], [tool.pytest.ini_options]\n\n2. Package structure under `src/ggs/`:\n   ```\n   src/ggs/__init__.py\n   src/ggs/cli.py          (placeholder)\n   src/ggs/corpus/__init__.py\n   src/ggs/corpus/scrape.py\n   src/ggs/corpus/parse_srigranth.py\n   src/ggs/corpus/normalize.py\n   src/ggs/corpus/tokenize.py\n   src/ggs/corpus/validate.py\n   src/ggs/analysis/__init__.py\n   src/ggs/analysis/match.py\n   src/ggs/analysis/features.py\n   src/ggs/analysis/tagger.py\n   src/ggs/analysis/stats.py\n   src/ggs/lexicon/__init__.py\n   src/ggs/lexicon/lint.py\n   src/ggs/lexicon/loader.py\n   src/ggs/output/__init__.py\n   src/ggs/output/report.py\n   src/ggs/output/web_bundle.py\n   src/ggs/output/audit.py\n   ```\n\n3. `tests/conftest.py` with basic pytest configuration\n\n### Design rationale\n- src-layout prevents the common pitfall where `import ggs` accidentally imports the source directory instead of the installed package\n- Separating corpus/analysis/lexicon/output mirrors the pipeline phases and keeps concerns clean\n- Using httpx instead of requests because it supports async (useful for future parallel scraping within rate limits)\n\n### Acceptance criteria\n- `uv sync` installs all dependencies without error\n- `python -c \"from ggs.corpus import normalize; print('ok')\"` works\n- `pytest --collect-only` discovers the test directory\n- `ruff check src/` returns clean\n\n### Blocks\nEverything. This is the root node.\n","created_at":"2026-02-14T00:11:48Z"}]}
{"id":"bd-298.2","title":"Create configuration files (config.yaml, ragas.yaml)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:54:33.995648Z","created_by":"hsingh","updated_at":"2026-02-14T01:08:48.173559Z","closed_at":"2026-02-14T01:08:48.173545Z","close_reason":"Created config/config.yaml with all pipeline settings (source, scraping, normalization, lexicon paths, cooccurrence, tagging with dimension rules and thresholds, register density, statistics, error handling, parallelism) and config/ragas.yaml with all 31 canonical ragas including Gurmukhi forms and ang ranges.","source_repo":".","compaction_level":0,"original_size":0,"labels":["scaffold"],"dependencies":[{"issue_id":"bd-298.2","depends_on_id":"bd-298","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-298.2","depends_on_id":"bd-298.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":17,"issue_id":"bd-298.2","author":"Harpreet Singh","text":"## Task: Create configuration files (config.yaml, ragas.yaml)\n\nAll pipeline behavior is driven by configuration, not hardcoded values. This task creates the two primary config files that all phases reference.\n\n### config/config.yaml\nThis is the master configuration file. It must include all settings from PLAN.md Section 9:\n\n```yaml\n# Source configuration\nsource:\n  primary: srigranth\n  cross_validate: [gurbaninow]\n  sample_size: 50\n\n# Scraping protocol\nang_start: 1\nang_end: 1430\nrequest_delay_ms_min: 500\nrequest_delay_ms_max: 1500\nmax_retries: 5\n\n# Normalization policies (Section 3.4)\nnormalization:\n  unicode: NFC\n  nukta_policy: PRESERVE\n  nasal_policy: CANONICAL_TIPPI\n  vishram_policy: STRIP\n  zwj_policy: STRIP\n  halant_policy: DECOMPOSE\n\n# Lexicon paths\nlexicon_paths:\n  entities: lexicon/entities.yaml\n  nirgun: lexicon/nirgun.yaml\n  sagun_narrative: lexicon/sagun_narrative.yaml\n  perso_arabic: lexicon/perso_arabic.yaml\n  sanskritic: lexicon/sanskritic.yaml\n\n# Co-occurrence (Section 5.1)\ncooccurrence:\n  min_entity_freq: 10\n  smoothing_k: 1\n  min_pmi_support: 5\n\n# Tagging (Section 6.1)\ntagging:\n  context_weight: 0.2\n  dimensions: ...\n\n# Error handling (Section 2.1)\nerror_handling:\n  max_record_errors: 100\n  strict_mode: false\n```\n\n### config/ragas.yaml\nCanonical list of all 31 ragas in the GGS. Each entry has the canonical Gurmukhi form, romanized form, and ang range. This is used by the parser to validate raga headers and by downstream analysis for raga-conditioned breakdowns.\n\n### Why config-driven\nHardcoded thresholds are the enemy of reproducibility. Every threshold, policy, and path must be in config so that:\n1. Different runs with different configs produce different (but reproducible) results\n2. Config is captured in run_manifest.json for provenance\n3. Sensitivity analysis is possible by varying one parameter at a time\n\n### Depends on\nbd-298.1 (package structure must exist to place config files)\n","created_at":"2026-02-14T00:11:48Z"}]}
{"id":"bd-298.3","title":"Define lexicon schema (_schema.yaml)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:54:34.778937Z","created_by":"hsingh","updated_at":"2026-02-14T01:08:48.202868Z","closed_at":"2026-02-14T01:08:48.202853Z","close_reason":"Created lexicon/_schema.yaml defining the full entity entry schema: required fields (id, canonical_form, aliases, category), optional fields (tradition, register, notes, polysemous, added_version), controlled vocabularies, and validation rules.","source_repo":".","compaction_level":0,"original_size":0,"labels":["lexicon","scaffold"],"dependencies":[{"issue_id":"bd-298.3","depends_on_id":"bd-298","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-298.3","depends_on_id":"bd-298.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":18,"issue_id":"bd-298.3","author":"Harpreet Singh","text":"## Task: Define lexicon schema (_schema.yaml)\n\nThe lexicon schema defines the contract that ALL lexicon YAML files must conform to. It is the single source of truth for what constitutes a valid lexicon entry.\n\n### Schema definition (from PLAN.md Section 4.1)\n\n```yaml\n# lexicon/_schema.yaml\nentity:\n  required:\n    id: string            # UPPER_SNAKE_CASE, globally unique\n    canonical_form: string # Gurmukhi Unicode\n    aliases: list          # Each: {form: string, type: exact|prefix|suffix}\n    category: enum         # See controlled vocabulary below\n  optional:\n    tradition: enum|null\n    register: enum\n    notes: string\n    polysemous: boolean\n    added_version: string  # semver\n```\n\n### Controlled vocabularies\n\n**category** (one of):\n- divine_name: names/epithets for the divine (ਅੱਲਾਹ, ਰਾਮ, ਹਰਿ)\n- concept: abstract theological/philosophical terms (ਹੁਕਮ, ਨਾਮ)\n- marker: register/style indicator\n- narrative: proper nouns from stories/examples (ਧ੍ਰੂ, ਪ੍ਰਹਿਲਾਦ)\n- place: geographic references (ਕਾਸ਼ੀ, ਮੱਕਾ)\n- practice: ritual/worship practices (ਤੀਰਥ, ਜਪ, ਪੂਜਾ)\n- negation: negation words for co-occurrence analysis\n- temporal: cosmological/time terms (ਜੁਗ, ਕਲਿਜੁਗ)\n\n**tradition** (one of):\n- islamic, vedantic, vaishnava, yogic, bhakti, universal, sikh, null\n\n**register** (one of):\n- perso_arabic, sanskritic, mixed, neutral\n\n### Why this matters\nThe lexicon is the analytical foundation. Every entity count, co-occurrence pair, and interpretive tag flows from lexicon definitions. If the schema is loose, garbage data propagates through all four phases. The linter (bd-4i2.2) validates against this schema, so it must be precise and complete.\n\n### Depends on\nbd-298.1 (package structure)\n","created_at":"2026-02-14T00:11:48Z"}]}
{"id":"bd-298.4","title":"Set up data directory structure and .gitignore","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-13T23:54:35.620060Z","created_by":"hsingh","updated_at":"2026-02-14T01:11:41.408122Z","closed_at":"2026-02-14T01:11:41.408110Z","close_reason":"Created data directory structure (raw_html, corpus, derived, reports, web_bundle/corpus, gold) and .cache. Added .gitkeep files to preserve empty dirs. Updated .gitignore to track reports/ and gold/ while ignoring regenerable artifacts (raw_html, corpus, derived, web_bundle, .cache).","source_repo":".","compaction_level":0,"original_size":0,"labels":["scaffold"],"dependencies":[{"issue_id":"bd-298.4","depends_on_id":"bd-298","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-298.4","depends_on_id":"bd-298.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":19,"issue_id":"bd-298.4","author":"Harpreet Singh","text":"## Task: Set up data directory structure and .gitignore\n\nCreate the full data directory tree and configure git to track structure but not large generated artifacts.\n\n### Directory structure\n```\ndata/\n  raw_html/           # Scraped HTML pages (gitignored, large)\n  corpus/             # Canonical corpus files\n    ggs_lines.jsonl   # Main corpus (gitignored, regenerable)\n    cross_validation.jsonl\n    manifest.json\n    validation_report.json\n  derived/            # Phase 1-3 outputs\n    matches.jsonl\n    features.jsonl\n    tags.jsonl\n  reports/            # Human-readable CSVs\n  web_bundle/         # Phase 4 input\n    corpus/           # Ang-range chunk files\n  gold/               # Gold standard labels\n    gold_labels.jsonl\n\n.cache/               # Incremental processing cache (gitignored)\n```\n\n### .gitignore rules\n- `data/raw_html/` — large, regenerable from scrape\n- `data/corpus/ggs_lines.jsonl` — regenerable (but published as GitHub Release)\n- `data/derived/` — all regenerable from pipeline\n- `data/web_bundle/` — regenerable from bundle step\n- `.cache/` — ephemeral optimization, never committed\n- Keep: `data/gold/`, `data/reports/` (small, curated)\n- Use `.gitkeep` files to preserve empty directory structure in git\n\n### Why separate .cache from data/\nPLAN.md Section 2 explicitly separates cache from data artifacts. Cache is an optimization that can be blown away without losing anything. Data artifacts have provenance and are published. Mixing them creates confusion about what's ephemeral vs. meaningful.\n\n### Depends on\nbd-298.1 (package structure must exist first)\n","created_at":"2026-02-14T00:11:48Z"}]}
{"id":"bd-2zi","title":"Phase 3: Interpretive Tagging","status":"closed","priority":2,"issue_type":"epic","created_at":"2026-02-13T23:54:23.132364Z","created_by":"hsingh","updated_at":"2026-02-14T04:01:33.606937Z","closed_at":"2026-02-14T04:01:33.606926Z","close_reason":"Phase 3 interpretive tagging complete - scores, tagger, evaluation","source_repo":".","compaction_level":0,"original_size":0,"comments":[{"id":20,"issue_id":"bd-2zi","author":"Harpreet Singh","text":"## Epic: Phase 3 — Interpretive Tagging\n\nPhase 3 is where the project crosses from pure counting into bounded interpretation. It assigns continuous scores and categorical tags to each line along dimensions like nirgun/sagun, universalism, and critique-of-ritual.\n\n### Critical principle: rule-first, evidence-attached\nEvery tag includes: the rules that fired, the evidence tokens, and the score breakdown. This is NOT a black box. A reviewer can look at any tagged line and understand exactly WHY it was tagged that way and HOW the score was computed.\n\n### The nirgun/sagun spectrum\nThe most analytically significant dimension. The GGS contains both:\n- **Nirgun** (formless) theology: God as beyond form, name, attribute\n- **Sagun** (with form) references: stories, avatars, mythological characters\n\nMost scholarly analysis treats these as a binary. Our approach uses continuous scores (0.0 to 1.0), acknowledging that many lines contain elements of both, and the boundary is genuinely fuzzy.\n\n### Disclaimer\nThis phase is explicitly \"descriptive, not doctrinal\" (AGENTS.md). The tags describe patterns in the text; they do not make theological claims about what the Gurus intended.\n\n### Children\n- bd-2zi.1: Score computation engine (mathematical framework)\n- bd-2zi.2: Tagging rules configuration (what rules exist, what weights)\n- bd-2zi.3: Tag generation (wire it all together)\n- bd-2zi.4: Category derivation (continuous → categorical labels)\n- bd-2zi.5: Gold set evaluation (how good are our tags?)\n","created_at":"2026-02-14T00:11:44Z"}]}
{"id":"bd-2zi.1","title":"Implement score computation engine (raw + context + sigmoid)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:55:05.519559Z","created_by":"hsingh","updated_at":"2026-02-14T03:09:20.218971Z","closed_at":"2026-02-14T03:09:20.218960Z","close_reason":"Implemented score computation engine with raw signal, context signal (shabad-level), combined signal, and sigmoid squashing. Includes config parsing, rule evaluation (match_entity, match_register, negation, co-occurrence), and end-to-end compute_all_scores. 37 tests passing.","source_repo":".","compaction_level":0,"original_size":0,"labels":["phase3","tagging"],"dependencies":[{"issue_id":"bd-2zi.1","depends_on_id":"bd-2zi","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2zi.1","depends_on_id":"bd-4i2.5","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2zi.1","depends_on_id":"bd-9qw.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":21,"issue_id":"bd-2zi.1","author":"Harpreet Singh","text":"## Task: Implement score computation engine (raw + context + sigmoid)\n\nThis task implements the mathematical framework that converts Phase 1 matches and Phase 2 features into continuous dimension scores.\n\n### Score formula (PLAN.md Section 6.1)\n\nFor dimension D and line L:\n\n```\nraw_signal(D, L)     = sum of weights for all rules that fire on L for dimension D\ncontext_signal(D, L) = mean(raw_signal(D, neighbor)) for neighbors in same shabad\ncombined(D, L)       = (1 - context_weight) * raw_signal + context_weight * context_signal\nscore(D, L)          = sigmoid(combined(D, L))\n```\n\n### Why sigmoid?\nThe raw signal is an unbounded sum of rule weights. A line matching 5 nirgun entities would have a much higher raw signal than a line matching 1. The sigmoid squashes this to [0, 1]:\n- `sigmoid(x) = 1 / (1 + exp(-k * (x - x0)))`\n- `k` (steepness) and `x0` (midpoint) are configurable per dimension\n- This ensures scores are interpretable as \"degree of dimension presence\"\n\n### Why context signal?\nA line in isolation might not have strong nirgun markers, but if it's in a shabad where every other line is strongly nirgun, the context suggests it participates in that theme. The context_weight (default 0.2) gives modest weight to shabad-level context while keeping the line's own evidence dominant.\n\n### Rules framework\nEach dimension has a list of rules with weights. Rules fire based on:\n- `match_entity: [ENTITY_IDS]` — entities found on this line\n- `match_register: REGISTER` — register density above threshold\n- `has_negation_of_form: true` — negation pattern detected\n- `co_occurs_negation: true` — ritual+negation co-occurrence\n\n### Implementation\n- Input: matches.jsonl (Phase 1) + features.jsonl (Phase 2)\n- Group lines by shabad for context computation\n- Evaluate all rules per line per dimension\n- Compute raw → context → combined → sigmoid\n\n### Depends on\nbd-4i2.5 (matches — rules reference entity matches)\nbd-9qw.1 (features — rules reference density scores)\n","created_at":"2026-02-14T00:12:05Z"}]}
{"id":"bd-2zi.2","title":"Define tagging rules configuration in config.yaml","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:55:06.481677Z","created_by":"hsingh","updated_at":"2026-02-14T01:21:23.890222Z","closed_at":"2026-02-14T01:21:23.890209Z","close_reason":"Tagging rules configuration was already defined in config/config.yaml as part of bd-298.2. Includes all 5 dimensions (nirgun, sagun_narrative, critique_ritual, universalism, critique_clerics) with sigmoid parameters, rule weights, and category derivation thresholds.","source_repo":".","compaction_level":0,"original_size":0,"labels":["phase3","tagging"],"dependencies":[{"issue_id":"bd-2zi.2","depends_on_id":"bd-298.2","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2zi.2","depends_on_id":"bd-2zi","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":22,"issue_id":"bd-2zi.2","author":"Harpreet Singh","text":"## Task: Define tagging rules configuration in config.yaml\n\nThis task defines the actual rules, weights, and thresholds that drive Phase 3 scoring. These are in config, not code, so they can be tuned without code changes.\n\n### Configuration structure (PLAN.md Section 6.1)\n\n```yaml\ntagging:\n  context_weight: 0.2\n  dimensions:\n    nirgun:\n      sigmoid_k: 2.0\n      sigmoid_x0: 1.5\n      rules:\n        - match_entity: [WAHEGURU, NIRANKAR, FORMLESS_EPITHETS]\n          weight: 1.0\n        - match_register: sanskritic\n          weight: 0.3\n        - has_negation_of_form: true\n          weight: 0.8\n    sagun_narrative:\n      sigmoid_k: 2.0\n      sigmoid_x0: 1.5\n      rules:\n        - match_entity: [RAM_NARRATIVE, KRISHNA_NARRATIVE, SHIVA]\n          weight: 1.0\n        - match_register: perso_arabic\n          weight: 0.0\n    critique_ritual:\n      sigmoid_k: 2.5\n      sigmoid_x0: 1.0\n      rules:\n        - match_entity: [RITUAL_MARKERS]\n          weight: 0.5\n        - co_occurs_negation: true\n          weight: 1.5\n```\n\n### Dimensions to configure\n1. **nirgun**: Formless theology (nirgun entities + sanskritic register + negation-of-form patterns)\n2. **sagun_narrative**: Formed/narrative references (mythological entities, avatar stories)\n3. **universalism**: Cross-tradition synthesis (co-occurrence of entities from different traditions)\n4. **critique_ritual**: Critique of external ritual (ritual terms + negation)\n5. **critique_clerics**: Critique of religious intermediaries\n\n### Category derivation thresholds (Section 6.2)\n```yaml\nthresholds:\n  nirgun_leaning: {nirgun_min: 0.6, sagun_max: 0.3}\n  sagun_narrative_leaning: {sagun_min: 0.6, nirgun_max: 0.3}\n  mixed: {diff_max: 0.3, both_min: 0.2}\n  universalism: {min: 0.5}\n  critique_ritual: {min: 0.5}\n  critique_clerics: {min: 0.5}\n```\n\n### Design: thresholds are explicit config\nThese thresholds are analytical choices, not objective facts. Making them config means:\n1. Sensitivity analysis: vary thresholds, see how distributions change\n2. Transparency: anyone can see exactly what \"nirgun_leaning\" means\n3. Reproducibility: same config → same tags\n\n### Depends on\nbd-298.2 (config.yaml — this extends the main config file)\n","created_at":"2026-02-14T00:12:05Z"}]}
{"id":"bd-2zi.3","title":"Implement tag generation (tagger.py)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:55:07.302648Z","created_by":"hsingh","updated_at":"2026-02-14T03:29:29.554543Z","closed_at":"2026-02-14T03:29:29.554530Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["phase3","tagging"],"dependencies":[{"issue_id":"bd-2zi.3","depends_on_id":"bd-2zi","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2zi.3","depends_on_id":"bd-2zi.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2zi.3","depends_on_id":"bd-2zi.2","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":23,"issue_id":"bd-2zi.3","author":"Harpreet Singh","text":"## Task: Implement tag generation (tagger.py)\n\nThis is the integration point for Phase 3 — it wires the score engine, rules config, and category derivation into a complete tagging pipeline that produces tags.jsonl.\n\n### Tag record schema (PLAN.md Section 6.2)\n```json\n{\n  \"line_uid\": \"...\",\n  \"scores\": {\n    \"nirgun\": 0.82,\n    \"sagun_narrative\": 0.05,\n    \"universalism\": 0.45,\n    \"critique_ritual\": 0.70,\n    \"critique_clerics\": 0.0\n  },\n  \"primary_tag\": \"nirgun_leaning\",\n  \"secondary_tags\": [\"critique_ritual\"],\n  \"rules_fired\": [\"match_entity:WAHEGURU\", \"has_negation_of_form\"],\n  \"evidence_tokens\": [\"ਵਾਹਿਗੁਰੂ\", \"ਰੂਪੁ ਨ ਰੇਖ\"],\n  \"score_breakdown\": {\n    \"nirgun\": [\n      {\"rule\": \"match_entity:WAHEGURU\", \"weight\": 1.0, \"matched\": \"ਵਾਹਿਗੁਰੂ\"},\n      {\"rule\": \"has_negation_of_form\", \"weight\": 0.8, \"matched\": \"ਰੂਪੁ ਨ ਰੇਖ\"}\n    ],\n    \"critique_ritual\": [\n      {\"rule\": \"co_occurs_negation:RITUAL\", \"weight\": 1.5, \"matched\": \"ਤੀਰਥਿ...ਨਾ\"}\n    ]\n  }\n}\n```\n\n### Pipeline flow\n1. Load corpus (ggs_lines.jsonl), matches (matches.jsonl), features (features.jsonl)\n2. Load tagging rules from config\n3. Group lines by shabad\n4. For each shabad, for each line:\n   a. Evaluate all rules → raw_signal per dimension\n   b. Compute context_signal from shabad neighbors\n   c. Apply sigmoid → continuous scores\n   d. Derive primary_tag and secondary_tags from thresholds\n   e. Assemble full evidence trail (rules_fired, evidence_tokens, score_breakdown)\n5. Write tags.jsonl\n6. Generate nirgun_sagun_distribution.csv\n\n### Multiple secondary tags\nA line can be nirgun AND critique_ritual simultaneously. Tags are not mutually exclusive. This is more faithful to the text than forcing a single category.\n\n### Parallelism\nParallelizable by shabad (each shabad is processed independently for context computation). Uses ProcessPoolExecutor.\n\n### Depends on\nbd-2zi.1 (score computation engine)\nbd-2zi.2 (tagging rules configuration)\n","created_at":"2026-02-14T00:12:05Z"}]}
{"id":"bd-2zi.4","title":"Implement category derivation with configurable thresholds","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-13T23:55:08.225037Z","created_by":"hsingh","updated_at":"2026-02-14T03:43:31.417158Z","closed_at":"2026-02-14T03:43:31.417145Z","close_reason":"Implemented configurable category derivation with detailed distribution breakdowns. Added ang/author/raga metadata to TagRecord, generate_detailed_distribution() with breakdowns by overall/author/raga/ang_bucket, _ang_bucket() helper, rederive_tags() for threshold re-application, run_sensitivity_analysis() for multi-variant threshold testing. run_tagger now writes nirgun_sagun_distribution_detailed.csv. 33 new tests (61 total for tagger), 559 total passing.","source_repo":".","compaction_level":0,"original_size":0,"labels":["phase3","tagging"],"dependencies":[{"issue_id":"bd-2zi.4","depends_on_id":"bd-2zi","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2zi.4","depends_on_id":"bd-2zi.3","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":24,"issue_id":"bd-2zi.4","author":"Harpreet Singh","text":"## Task: Implement category derivation with configurable thresholds\n\nThis task maps continuous scores to categorical labels. While scores are the primary output, categories are needed for summary statistics, filtering in the webapp, and human communication.\n\n### Derivation rules (PLAN.md Section 6.2)\n\n```\nnirgun_leaning:          nirgun > 0.6 AND sagun < 0.3\nsagun_narrative_leaning: sagun > 0.6 AND nirgun < 0.3\nmixed:                   |nirgun - sagun| < 0.3 AND both > 0.2\nuniversalism:            universalism > 0.5\ncritique_ritual:         critique_ritual > 0.5\ncritique_clerics:        critique_clerics > 0.5\n```\n\n### primary_tag assignment\nThe primary_tag is the category with the highest score above its threshold. If no dimension exceeds threshold, primary_tag = null (unclassified).\n\n### secondary_tags\nAll categories that meet their threshold become secondary_tags, excluding the primary. A line can have 0-N secondary tags.\n\n### Why thresholds are configurable\nThe thresholds above (0.6, 0.3, 0.5, etc.) are analytical choices. Different scholars might prefer different boundaries. By making them config-driven:\n1. We can run sensitivity analyses: \"what happens to the nirgun distribution if we lower the threshold to 0.5?\"\n2. The webapp could potentially offer threshold sliders for exploration\n3. No pretense that our specific thresholds are \"correct\" — they're transparent analytical choices\n\n### Output\nAdds primary_tag and secondary_tags fields to each tag record in tags.jsonl.\nAlso generates nirgun_sagun_distribution.csv with category counts by author, raga, ang bucket.\n\n### Depends on\nbd-2zi.3 (tag generation — categories are derived from continuous scores)\n","created_at":"2026-02-14T00:12:05Z"}]}
{"id":"bd-2zi.5","title":"Build gold set and evaluation framework (P/R metrics)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-13T23:55:09.332021Z","created_by":"hsingh","updated_at":"2026-02-14T03:46:30.427757Z","closed_at":"2026-02-14T03:46:30.427744Z","close_reason":"Implemented gold set evaluation framework: GoldLabel dataclass with load/save JSONL, compute_category_metrics for per-category P/R/F1, evaluate() for full multi-category evaluation with macro averages, threshold_sweep() for multi-variant evaluation, collect_errors() and error_confusion_matrix() for error analysis, stratified_sample() for proportional gold set selection, generate_evaluation_csv() for reports, run_evaluation() end-to-end pipeline. 46 tests, 605 total passing.","source_repo":".","compaction_level":0,"original_size":0,"labels":["evaluation","phase3"],"dependencies":[{"issue_id":"bd-2zi.5","depends_on_id":"bd-2zi","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-2zi.5","depends_on_id":"bd-2zi.3","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":25,"issue_id":"bd-2zi.5","author":"Harpreet Singh","text":"## Task: Build gold set and evaluation framework (P/R metrics)\n\nThis task creates a manually-annotated gold standard and measures how well our automated tagging agrees with human judgment.\n\n### Gold set creation (PLAN.md Section 6.2)\n\n1. **Stratified sampling**: Select lines covering:\n   - All authors (proportional representation)\n   - All raga sections\n   - All ang ranges\n   - Diverse density profiles (high nirgun, high sagun, mixed, neutral)\n   - Edge cases (rahao lines, very short lines, lines with polysemous entities)\n   - Target: ~500-1000 lines (large enough for meaningful P/R, small enough to annotate)\n\n2. **Manual annotation**: For each sampled line, a human annotator assigns:\n   - Ground truth category (nirgun/sagun/mixed/universalism/critique_ritual/other)\n   - Confidence level (certain/probable/uncertain)\n   - Notes explaining the judgment\n\n3. **Storage**: `data/gold/gold_labels.jsonl` — one record per annotated line with line_uid, ground truth labels, annotator, and notes.\n\n### Evaluation metrics\n\nFor each category:\n- **Precision**: Of lines our tagger labeled as category X, what fraction does the gold set agree with?\n- **Recall**: Of lines the gold set labels as category X, what fraction did our tagger find?\n- **F1**: Harmonic mean of P and R\n\nEvaluated per-category AND per-threshold-boundary (how do P/R change as we vary thresholds?).\n\n### Why this matters\nWithout evaluation, our tags are unvalidated claims. The gold set provides:\n1. A quality measure: \"our nirgun tagging has 0.85 precision and 0.78 recall\"\n2. Error analysis: \"most false positives are lines where ਰਾਮ was interpreted as divine vs. narrative\"\n3. Improvement signal: \"adding rule X improved recall by 0.05\"\n\n### Depends on\nbd-2zi.3 (tag generation — need tags to evaluate)\n","created_at":"2026-02-14T00:12:05Z"}]}
{"id":"bd-3jj","title":"Testing & Quality Assurance","status":"closed","priority":1,"issue_type":"epic","created_at":"2026-02-13T23:54:24.284292Z","created_by":"hsingh","updated_at":"2026-02-14T04:01:33.554834Z","closed_at":"2026-02-14T04:01:33.554823Z","close_reason":"Testing complete - 713 tests across 21 modules","source_repo":".","compaction_level":0,"original_size":0,"comments":[{"id":26,"issue_id":"bd-3jj","author":"Harpreet Singh","text":"## Epic: Testing & Quality Assurance\n\nTesting is not an afterthought — it is load-bearing infrastructure. For a project making analytical claims about a sacred text, correctness is paramount. Every number we publish must be verifiable.\n\n### Three-layer testing strategy (PLAN.md Section 10)\n\n1. **Unit tests (pytest)**: Each module tested in isolation with known inputs/outputs\n2. **Property-based tests (hypothesis)**: Invariants verified across randomly generated inputs\n3. **Roundtrip tests**: Full pipeline determinism — same inputs always produce byte-identical outputs\n\n### Test-alongside-implementation philosophy\nEach test task depends on its corresponding implementation task. The intent is: implement a module, then immediately write its tests in the same session. Not \"we'll add tests later.\"\n\n### CI integration\nAll tests run in GitHub Actions on every push. The CI pipeline (bd-3jj.10) depends on ALL test tasks — it's the final quality gate.\n\n### Children\n- bd-3jj.1: Test fixtures (Ang 1-5 HTML snapshots + expected outputs)\n- bd-3jj.2: Parser regression tests\n- bd-3jj.3: Normalization tests\n- bd-3jj.4: Tokenizer tests\n- bd-3jj.5: Match tests\n- bd-3jj.6: Feature tests\n- bd-3jj.7: Tagger tests\n- bd-3jj.8: Property-based tests (cross-cutting)\n- bd-3jj.9: Roundtrip/determinism tests (cross-cutting)\n- bd-3jj.10: CI pipeline\n","created_at":"2026-02-14T00:11:44Z"}]}
{"id":"bd-3jj.1","title":"Create test fixtures (Ang 1-5 HTML snapshots and expected outputs)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:55:19.394437Z","created_by":"hsingh","updated_at":"2026-02-14T01:14:43.495487Z","closed_at":"2026-02-14T01:14:43.495474Z","close_reason":"Created test fixtures: HTML snapshots for angs 1-5 (realistic SriGranth HTML with class=gurbani td elements), normalization test cases YAML with 11 cases (basic, ZWJ, whitespace, nasal, vishram, idempotency, nukta policies, empty/whitespace), test lexicon with 5 entities (SATNAM, NAAM, HUKAM, TEERATH, NIRANJAN). Updated conftest.py with fixtures for HTML, normalization cases, lexicon, and sample Gurmukhi lines.","source_repo":".","compaction_level":0,"original_size":0,"labels":["testing"],"dependencies":[{"issue_id":"bd-3jj.1","depends_on_id":"bd-298.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.1","depends_on_id":"bd-3jj","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":27,"issue_id":"bd-3jj.1","author":"Harpreet Singh","text":"## Task: Create test fixtures (Ang 1-5 HTML snapshots and expected outputs)\n\nTest fixtures are the bedrock of the test suite. They provide deterministic, offline test data that doesn't require network access or a live scrape.\n\n### What to create\n\n1. **HTML snapshots**: Save the actual HTML from SriGranth.org for angs 1-5 as static files in tests/fixtures/\n   - `tests/fixtures/html/ang_001.html` through `ang_005.html`\n   - These are the ground truth for parser regression tests\n\n2. **Expected parser output**: The canonical records we expect the parser to produce from the above HTML\n   - `tests/fixtures/expected/corpus_ang_001_005.jsonl`\n   - Manually verified to be correct\n\n3. **Expected normalized forms**: For each line, the expected output after normalization\n   - Covers all normalization policies (at least the defaults)\n\n4. **Expected token lists**: For each normalized line, expected tokens and token_spans\n\n5. **Lexicon test fixtures**: Small lexicon files with known entities for match testing\n   - `tests/fixtures/lexicon/test_entities.yaml`\n   - Known must-match and must-not-match cases\n\n6. **Expected match results**: For the fixture corpus + fixture lexicon, exact expected matches\n\n### Why Ang 1-5\nAng 1 contains the Mool Mantar (ੴ ਸਤਿ ਨਾਮੁ...) — the most recognizable and most analyzed passage in the GGS. Angs 1-5 cover the beginning of Japji Sahib (by Guru Nanak) and include diverse Gurmukhi forms. This is a well-understood passage that we can manually verify.\n\n### Offline-only\nCI must NEVER scrape live sites (PLAN.md Section 10). These fixtures enable full pipeline testing without network access.\n\n### Depends on\nbd-298.1 (package structure — needs tests/ directory)\n","created_at":"2026-02-14T00:12:11Z"}]}
{"id":"bd-3jj.10","title":"Set up GitHub Actions CI pipeline","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-13T23:55:26.797380Z","created_by":"hsingh","updated_at":"2026-02-14T00:12:12.095935Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["ci","testing"],"dependencies":[{"issue_id":"bd-3jj.10","depends_on_id":"bd-3jj","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.10","depends_on_id":"bd-3jj.2","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.10","depends_on_id":"bd-3jj.3","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.10","depends_on_id":"bd-3jj.4","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.10","depends_on_id":"bd-3jj.5","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.10","depends_on_id":"bd-3jj.6","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.10","depends_on_id":"bd-3jj.7","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.10","depends_on_id":"bd-3jj.8","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.10","depends_on_id":"bd-3jj.9","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":28,"issue_id":"bd-3jj.10","author":"Harpreet Singh","text":"## Task: Set up GitHub Actions CI pipeline\n\nThe CI pipeline runs ALL quality gates on every push. It is the last line of defense against bugs reaching the main branch.\n\n### CI steps (PLAN.md Section 10)\n\n1. **Unit tests**: `pytest tests/ -k \"not test_properties and not test_roundtrip\"` (fast)\n2. **Parser regression tests**: Part of unit tests, uses fixture HTML\n3. **Property-based tests**: `pytest tests/test_properties.py --hypothesis-seed=0` (fixed seed)\n4. **Lexicon lint**: `python -m ggs.lexicon.lint` (all lexicon files valid)\n5. **Smoke pipeline on Ang 1-5**: Run full pipeline on fixtures, verify outputs match expected\n6. **JSON schema validation**: Validate all output artifacts against JSON schemas\n7. **Type checking**: `uvx ty check` (no type errors)\n8. **Linting**: `ruff check src/` (no lint errors)\n\n### What CI must NOT do\n- Scrape live websites (no network-dependent tests)\n- Require large data files (fixtures only)\n- Take more than 5 minutes (if slow, something is wrong)\n\n### GitHub Actions configuration\n```yaml\non: [push, pull_request]\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: astral-sh/setup-uv@v3\n      - run: uv sync\n      - run: ruff check src/\n      - run: uvx ty check\n      - run: pytest\n      - run: python -m ggs.lexicon.lint\n```\n\n### Dependencies\nDepends on ALL test tasks — CI can only be set up after tests exist.\n","created_at":"2026-02-14T00:12:12Z"}]}
{"id":"bd-3jj.2","title":"Implement parser regression tests (test_parse.py)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:55:20.359223Z","created_by":"hsingh","updated_at":"2026-02-14T01:18:31.729709Z","closed_at":"2026-02-14T01:18:31.729697Z","close_reason":"Implemented parser regression tests: basic extraction (line count, mool mantar, ang number), all 5 fixture angs parametrized, line ordering, rahao detection, canonical record conversion, UID computation, edge cases (empty HTML, no Gurmukhi, malformed). 29 tests passing.","source_repo":".","compaction_level":0,"original_size":0,"labels":["phase0","testing"],"dependencies":[{"issue_id":"bd-3jj.2","depends_on_id":"bd-15c.3","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.2","depends_on_id":"bd-3jj","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.2","depends_on_id":"bd-3jj.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":29,"issue_id":"bd-3jj.2","author":"Harpreet Singh","text":"## Task: Implement parser regression tests (test_parse.py)\n\nParser regression tests verify that the SriGranth HTML parser extracts the correct Gurmukhi text and metadata from known HTML fixtures.\n\n### Test cases\n\n1. **Basic extraction**: Parse fixture HTML for ang 1, verify each line's gurmukhi_raw matches expected text\n2. **All 5 angs**: Parse all fixture angs, verify total line count and line_id sequence\n3. **Metadata extraction**: Verify author, raga, shabad_id, rahao fields for known lines\n4. **Line ordering**: Lines must be in page order (line_id sequence is monotonic)\n5. **No data loss**: Every visible Gurmukhi line in the HTML produces a record (no silent drops)\n6. **Edge cases**: Handle pages with mixed content, continuation shabads, empty sections\n7. **Regression guard**: If we change the parser, these tests catch unintended output changes\n\n### Test structure\n```python\ndef test_parse_ang1_line_count():\n    \"\"\"Ang 1 should produce exactly N lines.\"\"\"\n\ndef test_parse_ang1_mool_mantar():\n    \"\"\"First line of ang 1 must be the Mool Mantar.\"\"\"\n\ndef test_parse_metadata_author():\n    \"\"\"Ang 1 lines should have author=M1 (Guru Nanak).\"\"\"\n\ndef test_parse_rahao_detection():\n    \"\"\"Lines containing ਰਹਾਉ must have meta.rahao=true.\"\"\"\n```\n\n### Depends on\nbd-15c.3 (parser — the code being tested)\nbd-3jj.1 (fixtures — the test data)\n","created_at":"2026-02-14T00:12:11Z"}]}
{"id":"bd-3jj.3","title":"Implement normalization tests (test_normalize.py)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:55:21.232553Z","created_by":"hsingh","updated_at":"2026-02-14T01:18:31.702541Z","closed_at":"2026-02-14T01:18:31.702525Z","close_reason":"Implemented normalization tests: fixture-driven tests from YAML, step-level unit tests for all 7 steps, full pipeline tests, idempotency tests (parametrized and fixture-based), dual mode tests, config-from-dict tests. 39 tests passing.","source_repo":".","compaction_level":0,"original_size":0,"labels":["phase0","testing"],"dependencies":[{"issue_id":"bd-3jj.3","depends_on_id":"bd-15c.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.3","depends_on_id":"bd-3jj","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.3","depends_on_id":"bd-3jj.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":30,"issue_id":"bd-3jj.3","author":"Harpreet Singh","text":"## Task: Implement normalization tests (test_normalize.py)\n\nNormalization tests verify that the 7-step pipeline produces correct, consistent, and idempotent output.\n\n### Test cases\n\n1. **NFC normalization**: Composed vs. decomposed forms normalize to the same output\n2. **ZWJ/ZWNJ stripping**: Text with zero-width characters equals text without after normalization\n3. **Nukta policy PRESERVE**: ਖ਼ and ਖ remain distinct\n4. **Nukta policy STRIP**: ਖ਼ and ਖ collapse to ਖ\n5. **Nasal normalization**: ਸੰਤ (tippi) and ਸਂਤ (bindi) produce same output under CANONICAL_TIPPI\n6. **Vishram stripping**: Vishram markers are removed\n7. **Halant decomposition**: Pre-composed conjuncts decompose to base+halant+second\n8. **Whitespace normalization**: Multiple spaces collapse to one, leading/trailing trimmed\n9. **Idempotency**: normalize(normalize(x)) == normalize(x) for ALL test inputs\n10. **Known transforms**: Specific Gurmukhi strings with known before/after pairs\n11. **Identity preservation**: Text that's already normalized is unchanged\n12. **Empty/whitespace-only input**: Returns empty string (not None, not error)\n\n### Idempotency is the critical property\nIf normalization is not idempotent, the validator will flag the corpus (check #3 in validate.py). Idempotency means we can safely re-normalize without changing results. Every test input should be checked for this.\n\n### Depends on\nbd-15c.1 (normalization pipeline — the code being tested)\nbd-3jj.1 (fixtures — some test data comes from fixtures)\n","created_at":"2026-02-14T00:12:11Z"}]}
{"id":"bd-3jj.4","title":"Implement tokenizer tests (test_tokenize.py)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:55:21.892653Z","created_by":"hsingh","updated_at":"2026-02-14T01:21:00.640642Z","closed_at":"2026-02-14T01:21:00.640629Z","close_reason":"Implemented tokenizer tests: basic splitting, token_spans correctness (extraction, ordering, bounds, known positions), structural marker extraction (rahao, dandas, numerals), edge cases (empty, whitespace, mool mantar), parallel array invariant. 21 tests passing.","source_repo":".","compaction_level":0,"original_size":0,"labels":["phase0","testing"],"dependencies":[{"issue_id":"bd-3jj.4","depends_on_id":"bd-15c.2","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.4","depends_on_id":"bd-3jj","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.4","depends_on_id":"bd-3jj.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":31,"issue_id":"bd-3jj.4","author":"Harpreet Singh","text":"## Task: Implement tokenizer tests (test_tokenize.py)\n\nTokenizer tests verify correct splitting, structural marker extraction, and token_spans accuracy.\n\n### Test cases\n\n1. **Basic splitting**: \"ਸਤਿ ਨਾਮੁ ਕਰਤਾ\" → [\"ਸਤਿ\", \"ਨਾਮੁ\", \"ਕਰਤਾ\"]\n2. **token_spans correctness**: Spans match actual character positions in the gurmukhi string\n3. **Structural marker extraction**: ਰਹਾਉ extracted to meta.structural_markers, not in tokens\n4. **Numeral extraction**: Gurmukhi numerals (੧, ੨, ...) extracted as structural markers\n5. **Double danda**: ॥ extracted as structural marker\n6. **Empty line**: Returns empty tokens list and empty spans\n7. **All-punctuation line**: Returns empty tokens after stripping\n8. **All-markers line**: Line like \"॥੧॥ ਰਹਾਉ ॥\" → empty tokens, populated structural_markers\n9. **Residual punctuation stripping**: Punctuation at token boundaries removed\n10. **Token count sanity**: Token count matches len(tokens) matches len(token_spans)\n11. **Span coverage**: Spans cover the full gurmukhi string (no gaps for actual tokens)\n12. **Span non-overlap**: No two spans in token_spans overlap\n\n### token_spans validation\nFor each test case, verify:\n- `gurmukhi[start:end] == token` for every (token, [start, end]) pair\n- Spans are in ascending order\n- No span extends beyond len(gurmukhi)\n\n### Depends on\nbd-15c.2 (tokenizer — the code being tested)\nbd-3jj.1 (fixtures — test data)\n","created_at":"2026-02-14T00:12:11Z"}]}
{"id":"bd-3jj.5","title":"Implement match tests (test_match.py)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:55:22.589960Z","created_by":"hsingh","updated_at":"2026-02-14T01:34:04.654919Z","closed_at":"2026-02-14T01:34:04.654906Z","close_reason":"29 match tests: must-match (7 entities tested), must-not-match (substring, prefix, empty), span accuracy (3 tests verifying offset correctness), overlap resolution (nested_in field, non-overlapping independence), confidence (HIGH/MEDIUM), boundary enforcement (left/right/both/mid-word), engine construction, MatchRecord serialization, corpus-level matching.","source_repo":".","compaction_level":0,"original_size":0,"labels":["phase1","testing"],"dependencies":[{"issue_id":"bd-3jj.5","depends_on_id":"bd-3jj","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.5","depends_on_id":"bd-3jj.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.5","depends_on_id":"bd-4i2.5","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":32,"issue_id":"bd-3jj.5","author":"Harpreet Singh","text":"## Task: Implement match tests (test_match.py)\n\nMatch tests verify the Aho-Corasick matching engine's correctness: right entities matched, right spans, right confidence, right overlap resolution.\n\n### Test categories\n\n**Must-match fixtures**: Known Gurmukhi strings that MUST produce specific matches.\n```python\ndef test_must_match_allah():\n    \"\"\"ਅਲਾਹੁ in text must match entity ALLAH.\"\"\"\n\ndef test_must_match_hari():\n    \"\"\"ਹਰਿ in text must match entity HARI.\"\"\"\n```\n\n**Must-not-match fixtures**: Strings that must NOT match (false positive guards).\n```python\ndef test_must_not_match_substring():\n    \"\"\"ਹਰਿਆ (green) must not match ਹਰਿ (Hari) due to boundary enforcement.\"\"\"\n```\n\n**Span accuracy**: Match spans are correct character offsets.\n```python\ndef test_span_correct_offset():\n    \"\"\"Match for ਨਾਮੁ in 'ਸਤਿ ਨਾਮੁ ਕਰਤਾ' should have span [4, 8].\"\"\"\n```\n\n**Overlap resolution**:\n```python\ndef test_nested_matches_both_kept():\n    \"\"\"SATNAM [0,9] containing NAAM [5,9] — both kept, shorter has nested_in.\"\"\"\n\ndef test_partial_overlap_longer_wins():\n    \"\"\"Partially overlapping matches: longer kept, shorter discarded.\"\"\"\n```\n\n**Confidence levels**:\n```python\ndef test_polysemous_match_medium_confidence():\n    \"\"\"ਰਾਮ (in polysemy registry) should produce confidence=MEDIUM.\"\"\"\n\ndef test_unambiguous_match_high_confidence():\n    \"\"\"ਅਲਾਹੁ (unique to ALLAH) should produce confidence=HIGH.\"\"\"\n```\n\n**Boundary enforcement**:\n```python\ndef test_word_boundary_required():\n    \"\"\"Entity must match on word boundaries, not as substring of larger word.\"\"\"\n```\n\n### Depends on\nbd-4i2.5 (matching engine — the code being tested)\nbd-3jj.1 (fixtures — test lexicon and corpus data)\n","created_at":"2026-02-14T00:12:11Z"}]}
{"id":"bd-3jj.6","title":"Implement feature tests (test_features.py)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-13T23:55:23.318494Z","created_by":"hsingh","updated_at":"2026-02-14T03:12:00.119669Z","closed_at":"2026-02-14T03:12:00.119656Z","close_reason":"Implemented 21 feature tests covering: empty features, density computation, entity classification, per-line features (zero matches, known density, bounds, nested exclusion, matched tokens, all dimensions, shabad propagation), and corpus-level batch processing.","source_repo":".","compaction_level":0,"original_size":0,"labels":["phase2","testing"],"dependencies":[{"issue_id":"bd-3jj.6","depends_on_id":"bd-3jj","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.6","depends_on_id":"bd-3jj.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.6","depends_on_id":"bd-9qw.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":33,"issue_id":"bd-3jj.6","author":"Harpreet Singh","text":"## Task: Implement feature tests (test_features.py)\n\nFeature tests verify that density scores are computed correctly from known match data.\n\n### Test cases\n\n1. **Zero matches → zero density**: Line with no matches for a register should have density 0.0\n2. **Known density**: Line with 3 perso_arabic matches out of 18 tokens → density 0.167\n3. **Density bounds**: All densities in [0.0, 1.0]\n4. **Density formula**: density = count / token_count for every feature\n5. **Matched tokens list**: matched_tokens field contains the actual matched forms\n6. **All registers computed**: Even registers with 0 matches have explicit entries with density 0.0\n7. **token_count field**: Matches the actual token count from the corpus line\n8. **shabad_uid propagation**: Each feature record includes correct shabad_uid from corpus\n\n### Property: density sum\nThe sum of all register densities CAN exceed 1.0 (a token can match in multiple registers). But each individual density must be <= 1.0.\n\n### Test with fixture data\nUse the fixture corpus (Ang 1-5) with the fixture lexicon to compute features, then verify against expected values.\n\n### Depends on\nbd-9qw.1 (feature computation — the code being tested)\nbd-3jj.1 (fixtures — test data)\n","created_at":"2026-02-14T00:12:11Z"}]}
{"id":"bd-3jj.7","title":"Implement tagger tests (test_tagger.py)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-13T23:55:24.108778Z","created_by":"hsingh","updated_at":"2026-02-14T04:00:09.396072Z","closed_at":"2026-02-14T04:00:09.396058Z","close_reason":"Implemented tagger tests: 25 new tests including threshold boundaries and precise score computation. 713 total tests passing.","source_repo":".","compaction_level":0,"original_size":0,"labels":["phase3","testing"],"dependencies":[{"issue_id":"bd-3jj.7","depends_on_id":"bd-2zi.3","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.7","depends_on_id":"bd-3jj","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.7","depends_on_id":"bd-3jj.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":34,"issue_id":"bd-3jj.7","author":"Harpreet Singh","text":"## Task: Implement tagger tests (test_tagger.py)\n\nTagger tests verify that the scoring engine, rules, and category derivation produce correct tags for known inputs.\n\n### Test cases\n\n1. **Rule firing**: Given a line with entity WAHEGURU, the rule match_entity:[WAHEGURU] must fire for nirgun dimension\n2. **Score computation**: Given known rules that fire with known weights, verify the combined score matches expected value\n3. **Sigmoid output**: Verify sigmoid(combined) produces expected value for known k, x0 parameters\n4. **Context signal**: Line in a shabad with high nirgun neighbors gets context boost\n5. **Category derivation**: Score 0.82 nirgun + 0.05 sagun → primary_tag = nirgun_leaning\n6. **Mixed category**: |nirgun - sagun| < 0.3, both > 0.2 → primary_tag = mixed\n7. **Multiple secondary tags**: Line can be nirgun AND critique_ritual simultaneously\n8. **Evidence trail**: score_breakdown accurately lists which rules contributed which weights\n9. **Threshold boundary**: Score exactly at threshold boundary → correct category assignment\n10. **No rules fire**: Line with no matches → all scores near 0 after sigmoid → primary_tag = null\n\n### Boundary case testing\nThe thresholds (0.6, 0.3, 0.5) create category boundaries. Test lines with scores just above, just below, and exactly at each boundary.\n\n### Depends on\nbd-2zi.3 (tagger — the code being tested)\nbd-3jj.1 (fixtures — test data)\n","created_at":"2026-02-14T00:12:11Z"}]}
{"id":"bd-3jj.8","title":"Implement property-based tests with hypothesis (test_properties.py)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:55:24.993525Z","created_by":"hsingh","updated_at":"2026-02-14T03:10:49.739827Z","closed_at":"2026-02-14T03:10:49.739814Z","close_reason":"Implemented 15 property-based tests with Hypothesis covering: normalization idempotency, tokenization span validity, match span bounds, no crossing overlaps, feature density bounds, density formula, co-occurrence pair ordering, and sigmoid bounds.","source_repo":".","compaction_level":0,"original_size":0,"labels":["testing"],"dependencies":[{"issue_id":"bd-3jj.8","depends_on_id":"bd-15c.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.8","depends_on_id":"bd-15c.2","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.8","depends_on_id":"bd-3jj","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.8","depends_on_id":"bd-4i2.5","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":35,"issue_id":"bd-3jj.8","author":"Harpreet Singh","text":"## Task: Implement property-based tests with hypothesis (test_properties.py)\n\nProperty-based testing uses random input generation to verify invariants that must hold for ALL inputs, not just hand-picked test cases. This catches edge cases that humans would never think to test.\n\n### Properties to test (PLAN.md Section 10)\n\n1. **Normalization is idempotent**:\n   `normalize(normalize(x)) == normalize(x)`\n   Strategy: generate random Gurmukhi strings (Unicode range 0x0A00-0x0A7F + common punctuation)\n\n2. **Tokenization roundtrip**:\n   `\" \".join(tokenize(line).tokens)` approximates line (modulo structural markers)\n   Strategy: generate normalized Gurmukhi strings\n\n3. **Match spans are valid**:\n   All match spans fall within `[0, len(gurmukhi)]`\n   Strategy: generate random strings with known entity substrings embedded\n\n4. **Match spans align to token_spans**:\n   Every match span start/end aligns to some token_span boundary\n   Strategy: generate lines with known tokens and entities\n\n5. **Match spans don't partially overlap for same entity**:\n   No two matches for the SAME entity have crossing (non-nested) spans\n   Strategy: generate strings with repeated entity patterns\n\n6. **Feature densities in [0.0, 1.0]**:\n   Every density value is bounded\n   Strategy: generate random match counts and token counts\n\n7. **Feature density = count / token_count**:\n   The formula is correctly applied\n   Strategy: generate random feature inputs\n\n### Why hypothesis\nHypothesis generates thousands of random inputs per property, shrinking to minimal failing cases. It finds bugs that hand-crafted tests miss: empty strings, single-character inputs, Unicode edge cases, extremely long lines, etc.\n\n### Fixed seed for CI\nProperty tests use a fixed random seed in CI for determinism. Locally, they use random seeds for broader exploration.\n\n### Depends on\nbd-15c.1 (normalizer), bd-15c.2 (tokenizer), bd-4i2.5 (matcher)\n","created_at":"2026-02-14T00:12:12Z"}]}
{"id":"bd-3jj.9","title":"Implement roundtrip/determinism tests (test_roundtrip.py)","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-13T23:55:25.878156Z","created_by":"hsingh","updated_at":"2026-02-14T00:12:12.053331Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["integration","testing"],"dependencies":[{"issue_id":"bd-3jj.9","depends_on_id":"bd-15c.8","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.9","depends_on_id":"bd-2zi.3","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.9","depends_on_id":"bd-3jj","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.9","depends_on_id":"bd-4i2.5","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-3jj.9","depends_on_id":"bd-9qw.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":36,"issue_id":"bd-3jj.9","author":"Harpreet Singh","text":"## Task: Implement roundtrip/determinism tests (test_roundtrip.py)\n\nRoundtrip tests verify the most important quality property: running the full pipeline twice on the same inputs produces byte-identical outputs.\n\n### Tests (PLAN.md Section 10)\n\n1. **Full pipeline determinism**:\n   - Run Phase 0-3 on fixture corpus (Ang 1-5)\n   - Run the same pipeline again with identical inputs\n   - All output files must be byte-identical\n   - This catches: non-deterministic iteration order, timestamp leaks, random seeds, dict ordering issues\n\n2. **Schema validation on all outputs**:\n   - Every JSONL record in matches.jsonl conforms to match schema\n   - Every JSONL record in features.jsonl conforms to feature schema\n   - Every JSONL record in tags.jsonl conforms to tag schema\n   - manifest.json conforms to manifest schema\n   - validation_report.json conforms to validation schema\n\n3. **Cross-artifact consistency**:\n   - Every line_uid in matches.jsonl exists in ggs_lines.jsonl\n   - Every line_uid in features.jsonl exists in ggs_lines.jsonl\n   - Every line_uid in tags.jsonl exists in ggs_lines.jsonl\n   - Every entity_id in matches.jsonl exists in the loaded lexicon\n\n### Why byte-identical matters\nIf two runs produce different bytes for the same inputs, something is non-deterministic. This makes results unreproducible — a violation of the project's core principle. Common causes:\n- dict ordering (use sorted keys)\n- set iteration order (convert to sorted list)\n- floating point non-determinism (use round() to fixed precision)\n- timestamps embedded in output (use only in manifest, not per-record)\n\n### Depends on\nbd-15c.8 (Phase 0 integration), bd-4i2.5 (matching), bd-9qw.1 (features), bd-2zi.3 (tagger)\n— needs the full pipeline working\n","created_at":"2026-02-14T00:12:12Z"}]}
{"id":"bd-4i2","title":"Phase 1: Lexical Analysis","status":"closed","priority":1,"issue_type":"epic","created_at":"2026-02-13T23:54:21.962460Z","created_by":"hsingh","updated_at":"2026-02-14T04:01:33.497678Z","closed_at":"2026-02-14T04:01:33.497663Z","close_reason":"Phase 1 lexical analysis complete - matching engine, features, lexicon, linter, reports","source_repo":".","compaction_level":0,"original_size":0,"comments":[{"id":37,"issue_id":"bd-4i2","author":"Harpreet Singh","text":"## Epic: Phase 1 — Lexical Analysis\n\nPhase 1 performs strict, non-interpretive entity matching against the corpus. It answers: \"which known entities appear where, and how often?\" This is pure counting — no interpretation, no inference.\n\n### What Phase 1 does\n1. Loads lexicon definitions (YAML files conforming to _schema.yaml)\n2. Builds an Aho-Corasick automaton from all entity aliases\n3. Scans every line in the corpus, recording all matches with spans\n4. Assigns confidence levels (HIGH/MEDIUM/LOW) based on polysemy\n5. Resolves overlapping matches\n6. Produces match records, count reports, and web aggregates\n\n### Why Aho-Corasick\nThe lexicon will have hundreds of entities with thousands of aliases. Naive regex matching would be O(patterns * text). Aho-Corasick scans text once and finds all pattern matches simultaneously — O(text + matches). This is critical for a 60,000-line corpus.\n\n### Key outputs\n- `data/derived/matches.jsonl` — one record per match (line_uid, entity_id, span, confidence)\n- `data/reports/entity_counts*.csv` — counts by various dimensions\n- `data/web_bundle/aggregates.json` — pre-computed aggregations for webapp\n\n### Dependency structure\n- Lexicon tasks (loader, linter, files, polysemy) can be developed in parallel with Phase 0\n- The matching engine needs BOTH the lexicon loader AND the Phase 0 corpus\n- This creates a natural merge point: Phase 0 + lexicon → matching\n\n### Children\n- bd-4i2.1: Lexicon loader (can start after scaffold + schema)\n- bd-4i2.2: Lexicon linter (needs loader)\n- bd-4i2.3: Lexicon YAML files (needs schema)\n- bd-4i2.4: Polysemy registry (needs base lexicon files)\n- bd-4i2.5: Matching engine (THE critical merge point — needs loader + Phase 0)\n- bd-4i2.6: Confidence + overlap resolution (needs matching engine + polysemy)\n- bd-4i2.7: Reports + aggregates (needs matching engine)\n","created_at":"2026-02-14T00:11:44Z"}]}
{"id":"bd-4i2.1","title":"Implement lexicon YAML loader (loader.py)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:54:48.476177Z","created_by":"hsingh","updated_at":"2026-02-14T01:18:31.759651Z","closed_at":"2026-02-14T01:18:31.759637Z","close_reason":"Implemented lexicon YAML loader: Entity/Alias/LexiconIndex dataclasses, schema validation against controlled vocabularies, cross-file ID uniqueness check, alias-to-entities index for polysemy support, SHA-256 file hashing for provenance. Integrated with pipeline error model.","source_repo":".","compaction_level":0,"original_size":0,"labels":["lexicon","phase1"],"dependencies":[{"issue_id":"bd-4i2.1","depends_on_id":"bd-298.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-4i2.1","depends_on_id":"bd-298.3","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-4i2.1","depends_on_id":"bd-4i2","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":38,"issue_id":"bd-4i2.1","author":"Harpreet Singh","text":"## Task: Implement lexicon YAML loader (loader.py)\n\nThe lexicon loader reads all YAML lexicon files, validates them against _schema.yaml, resolves aliases, and builds data structures ready for the matching engine.\n\n### Responsibilities\n\n1. **Discover lexicon files**: Read paths from config.yaml's `lexicon_paths` section\n2. **Parse YAML**: Load each file, validate structure against _schema.yaml\n3. **Build entity registry**: A dict mapping entity_id → full entity record\n4. **Build alias index**: A dict mapping each alias surface form → list of entity_ids\n   - Multiple entities can share an alias (polysemy!) — the alias index must handle this\n5. **Validate constraints**:\n   - entity_ids are globally unique across all files\n   - category/tradition/register values are from controlled vocabulary\n   - canonical_form and all aliases are valid Gurmukhi Unicode\n6. **Compute lexicon hashes**: SHA256 of each file for provenance tracking\n\n### Output data structures\n```python\n@dataclass\nclass LexiconIndex:\n    entities: dict[str, Entity]           # entity_id -> Entity\n    alias_to_entities: dict[str, list[str]]  # surface_form -> [entity_ids]\n    file_hashes: dict[str, str]           # filename -> sha256\n```\n\n### Why separate from linter\nThe loader is the runtime path (used by the matching engine in production). The linter is the development-time QA tool. They share validation logic but have different concerns:\n- Loader: fast, fail on first error, produce usable data structures\n- Linter: thorough, report ALL issues, human-readable output\n\n### Depends on\nbd-298.1 (package structure)\nbd-298.3 (lexicon schema — defines what valid means)\n","created_at":"2026-02-14T00:12:00Z"}]}
{"id":"bd-4i2.2","title":"Implement lexicon linter (lint.py)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:54:49.220073Z","created_by":"hsingh","updated_at":"2026-02-14T01:21:00.703665Z","closed_at":"2026-02-14T01:21:00.703653Z","close_reason":"Implemented lexicon linter: 8 checks (schema conformance, duplicate aliases, required fields, normalization collisions, YAML validity, cross-file ID uniqueness, alias coverage, controlled vocabulary). Rich-formatted console output with table display.","source_repo":".","compaction_level":0,"original_size":0,"labels":["lexicon","phase1"],"dependencies":[{"issue_id":"bd-4i2.2","depends_on_id":"bd-298.3","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-4i2.2","depends_on_id":"bd-4i2","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-4i2.2","depends_on_id":"bd-4i2.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":39,"issue_id":"bd-4i2.2","author":"Harpreet Singh","text":"## Task: Implement lexicon linter (lint.py)\n\nThe linter is a comprehensive QA tool for lexicon files. Unlike the loader (which fails fast at runtime), the linter reports ALL issues for developer review.\n\n### Checks (PLAN.md Section 4.2)\n\n1. **Schema conformance**: All entries match _schema.yaml structure\n2. **Duplicate aliases**: Same surface form appearing in multiple entries (may be intentional polysemy — cross-reference with polysemy.yaml)\n3. **Missing required fields**: id, canonical_form, aliases, category\n4. **Normalization collisions**: Two different aliases that normalize to the same form (after running normalize.py). This would cause the matcher to find the same text but attribute it to different entities non-deterministically.\n5. **YAML validity**: Well-formed YAML, no syntax errors\n6. **Cross-file ID uniqueness**: No entity_id appears in two different lexicon files\n7. **Alias coverage**: Every alias normalizes to a valid Gurmukhi string (no empty results, no Latin characters)\n8. **Controlled vocabulary**: category, tradition, register values are from the defined enum sets\n\n### Output\nRich-formatted console output (per AGENTS.md: \"stylish and colorful using rich library\") showing:\n- PASS/FAIL per check with counts\n- Detailed list of violations with file:line references\n- Summary verdict\n\n### Must-match / must-not-match fixtures (Section 4.2)\nThe linter also validates against test fixtures:\n- Must-match: known Gurmukhi strings that MUST produce a match for a given entity\n- Must-not-match: strings that must NOT match (false positive guards)\n\n### Integration with CI\nThe linter runs in CI (bd-3jj.10) on every push. Lexicon changes that break the linter block the build.\n\n### Depends on\nbd-4i2.1 (loader — linter uses loader's parsing logic)\nbd-298.3 (schema — defines what valid means)\n","created_at":"2026-02-14T00:12:00Z"}]}
{"id":"bd-4i2.3","title":"Create initial lexicon YAML files","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:54:50.158617Z","created_by":"hsingh","updated_at":"2026-02-14T01:27:35.112376Z","closed_at":"2026-02-14T01:27:35.112363Z","close_reason":"Created 5 lexicon YAML files with 70 entities total: entities.yaml (20 core divine names, concepts, negations, temporal), nirgun.yaml (14 formless epithets and concepts), sagun_narrative.yaml (10 narrative figures and sagun concept), perso_arabic.yaml (12 Islamic/Sufi terms, practices, markers, places), sanskritic.yaml (14 Vedantic concepts, practices, markers, places). All pass loader validation and linter (0 errors, 0 warnings).","source_repo":".","compaction_level":0,"original_size":0,"labels":["lexicon","phase1"],"dependencies":[{"issue_id":"bd-4i2.3","depends_on_id":"bd-298.3","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-4i2.3","depends_on_id":"bd-4i2","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":40,"issue_id":"bd-4i2.3","author":"Harpreet Singh","text":"## Task: Create initial lexicon YAML files\n\nThis task creates the seed lexicon files that define the entities we're analyzing. These are the \"analytical vocabulary\" of the project — they determine what the matching engine looks for.\n\n### Files to create (per PLAN.md Section 1)\n\n1. **lexicon/entities.yaml** — Core divine names and general entities\n   - ਵਾਹਿਗੁਰੂ (WAHEGURU), ਹਰਿ (HARI), ਰਾਮ (RAM), ਗੋਬਿੰਦ (GOBIND), ਅੱਲਾਹ (ALLAH), etc.\n   - Each with canonical_form, aliases (spelling variants), category, tradition, register\n\n2. **lexicon/nirgun.yaml** — Nirgun (formless) divine names and concepts\n   - ਨਿਰੰਕਾਰ (NIRANKAR), ਅਕਾਲ (AKAL), ਅਲਖ (ALAKH), etc.\n   - These are key for Phase 3 nirgun/sagun analysis\n\n3. **lexicon/sagun_narrative.yaml** — Sagun (formed) narrative references\n   - ਕ੍ਰਿਸ਼ਨ (KRISHNA), ਰਾਮਚੰਦ (RAMCHANDRA), ਸ਼ਿਵ (SHIV), etc.\n   - Stories and mythological references used in the GGS\n\n4. **lexicon/perso_arabic.yaml** — Perso-Arabic register markers\n   - Terms from Islamic/Sufi tradition used in the GGS\n   - ਖ਼ੁਦਾ (KHUDA), ਮੁਰਸ਼ਿਦ (MURSHID), ਮੁਰੀਦ (MURID), etc.\n\n5. **lexicon/sanskritic.yaml** — Sanskritic register markers\n   - Terms from Vedantic/Sanskrit tradition\n   - ਬ੍ਰਹਮ (BRAHM), ਆਤਮਾ (ATMA), ਮੁਕਤਿ (MUKTI), etc.\n\n### Starting small, growing organically\nWe do NOT need to be exhaustive on day one. Start with the most prominent entities (high-frequency, unambiguous ones). The lexicon is designed to grow iteratively:\n- Each entry has `added_version` for tracking when it was introduced\n- The linter catches quality issues as entries are added\n- Match results reveal gaps: \"why didn't we match this common Gurmukhi word?\"\n\n### Research required\nCreating accurate lexicon entries requires understanding of:\n- Gurmukhi orthographic variants (different manuscripts use different spellings)\n- Which entities are polysemous (ਰਾਮ can mean God or Ramchandra)\n- Register classification (is this term Perso-Arabic or Sanskritic?)\n- Tradition mapping (which devotional tradition does this term belong to?)\n\n### Depends on\nbd-298.3 (lexicon schema — entries must conform to schema)\n","created_at":"2026-02-14T00:12:00Z"}]}
{"id":"bd-4i2.4","title":"Create polysemy registry (polysemy.yaml)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-13T23:54:51.097277Z","created_by":"hsingh","updated_at":"2026-02-14T01:34:36.729496Z","closed_at":"2026-02-14T01:34:36.729483Z","close_reason":"Created polysemy.yaml with 5 polysemous surface forms: ਰਾਮ/ਰਾਮੁ (RAM vs RAMCHANDRA — the most analytically important polysemy), ਕਰਮ (ritual actions vs divine grace), ਗੁਰੂ (GUR vs SATGUR). Each entry has context_hints for downstream disambiguation in Phase 3.","source_repo":".","compaction_level":0,"original_size":0,"labels":["lexicon","phase1"],"dependencies":[{"issue_id":"bd-4i2.4","depends_on_id":"bd-4i2","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-4i2.4","depends_on_id":"bd-4i2.3","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":41,"issue_id":"bd-4i2.4","author":"Harpreet Singh","text":"## Task: Create polysemy registry (polysemy.yaml)\n\nThe polysemy registry maps surface forms to multiple possible entity_ids. This is essential for intellectual honesty — when a word is genuinely ambiguous, we must say so rather than silently picking one interpretation.\n\n### The problem\nIn the GGS, many surface forms are genuinely polysemous:\n- **ਰਾਮ (Ram)**: Could refer to the divine (nirgun usage) OR to Ramchandra the avatar (sagun narrative). This is one of the most analytically important distinctions in the entire project.\n- **ਹਰਿ (Hari)**: Could be a generic divine name OR specifically Vishnu\n- **ਗੁਰੂ (Guru)**: Could mean the human Guru, the divine Guru, or the Shabad-Guru concept\n\n### Registry schema\n```yaml\npolysemy:\n  ਰਾਮ:\n    entities: [RAM_DIVINE, RAM_NARRATIVE]\n    context_hints:\n      - \"When preceded by nirgun markers, likely RAM_DIVINE\"\n      - \"When in mythological narrative context, likely RAM_NARRATIVE\"\n  ਹਰਿ:\n    entities: [HARI_DIVINE, HARI_VAISHNAVA]\n    context_hints:\n      - \"Default: HARI_DIVINE (most common usage in GGS)\"\n```\n\n### How it's used downstream\n- Phase 1 (matching): When the matcher finds \"ਰਾਮ\", it records BOTH possible entities with confidence=MEDIUM and populates the ambiguity field\n- Phase 3 (tagging): The tagger may resolve some ambiguities using context (shabad-level markers, surrounding entities)\n- Web app: Polysemous matches are displayed with appropriate uncertainty markers\n\n### Why this is P2\nThe matching engine works without polysemy — it just assigns all matches as HIGH confidence. Polysemy adds nuance and honesty but isn't blocking. We can add it after the basic matching pipeline works.\n\n### Depends on\nbd-4i2.3 (base lexicon files must exist to know which entities are polysemous)\n","created_at":"2026-02-14T00:12:00Z"}]}
{"id":"bd-4i2.5","title":"Implement Aho-Corasick matching engine (match.py)","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-13T23:54:52.084230Z","created_by":"hsingh","updated_at":"2026-02-14T01:32:42.227380Z","closed_at":"2026-02-14T01:32:42.227365Z","close_reason":"Implemented Aho-Corasick matching engine (match.py). Features: MatchingEngine.from_lexicon() builds automaton from all alias surface forms, word boundary enforcement, overlap resolution (nested kept with nested_in marker, crossing discards shorter), confidence scoring (HIGH/MEDIUM based on polysemy), MatchRecord dataclass with to_dict(), run_matching() batch API. Tested on Mool Mantar (7 matches including SATNAM/NAAM nesting) and boundary enforcement.","source_repo":".","compaction_level":0,"original_size":0,"labels":["matching","phase1"],"dependencies":[{"issue_id":"bd-4i2.5","depends_on_id":"bd-15c.8","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-4i2.5","depends_on_id":"bd-4i2","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-4i2.5","depends_on_id":"bd-4i2.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":42,"issue_id":"bd-4i2.5","author":"Harpreet Singh","text":"## Task: Implement Aho-Corasick matching engine (match.py)\n\nThis is the analytical engine of Phase 1 — the most performance-critical module in the project. It scans every line of the corpus against every lexicon entry simultaneously.\n\n### Algorithm: Aho-Corasick\n\nAho-Corasick is a multi-pattern string matching algorithm that:\n1. Builds a trie (prefix tree) from all patterns\n2. Adds failure links to create an automaton\n3. Scans text once, following the automaton, reporting all pattern matches\n\nTime complexity: O(text_length + number_of_matches), regardless of pattern count.\nThis is critical: with hundreds of entities and thousands of aliases, naive matching would be prohibitively slow on 60,000 lines.\n\n### Implementation (PLAN.md Section 4.3)\n\n1. **Build automaton**: From lexicon loader's alias index, compile all alias surface forms into an Aho-Corasick automaton (use `ahocorasick` or `pyahocorasick` library)\n2. **Scan each line**: For each line's `gurmukhi` field, run the automaton\n3. **Boundary enforcement**: Post-filter matches to ensure they fall on word boundaries (not substring matches within larger words)\n4. **Record matches**: Each match becomes a record with line_uid, entity_id, matched_form, span [start, end], rule_id, confidence\n\n### Span coordinate system\nAll spans are character offsets into the `gurmukhi` field (normalized form). This is the SAME string used for display in the webapp, so spans can be used directly for highlighting.\n\n### Match record schema (PLAN.md Section 4.3)\n```json\n{\n  \"line_uid\": \"...\",\n  \"entity_id\": \"ALLAH\",\n  \"matched_form\": \"ਅਲਾਹੁ\",\n  \"span\": [12, 18],\n  \"rule_id\": \"alias_exact\",\n  \"confidence\": \"HIGH\",\n  \"ambiguity\": null,\n  \"nested_in\": null\n}\n```\n\n### --profile mode\nFor development: a mode that reports matching performance per-entity and per-ang, to identify slow patterns or unexpected match distributions.\n\n### Why P0 priority\nThis is on the critical path for Phase 2 (features depend on matches), Phase 3 (tagger depends on matches), and the web bundle. Everything downstream of Phase 1 needs matches.jsonl.\n\n### Depends on\nbd-4i2.1 (lexicon loader — provides the alias data structures)\nbd-15c.8 (Phase 0 integration — provides the corpus to match against)\n","created_at":"2026-02-14T00:12:00Z"}]}
{"id":"bd-4i2.6","title":"Implement match confidence scoring and overlap resolution","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:54:53.148447Z","created_by":"hsingh","updated_at":"2026-02-14T01:34:51.415171Z","closed_at":"2026-02-14T01:34:51.415158Z","close_reason":"Already implemented as part of bd-4i2.5 (match.py). Confidence scoring in _build_records() assigns HIGH for unique forms, MEDIUM for polysemous forms. Overlap resolution in _resolve_overlaps() handles nested (both kept, shorter gets nested_in), crossing (longer wins), and equal-length cases. Ambiguity records populated with alternative_entities. All verified by 29 match tests.","source_repo":".","compaction_level":0,"original_size":0,"labels":["matching","phase1"],"dependencies":[{"issue_id":"bd-4i2.6","depends_on_id":"bd-4i2","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-4i2.6","depends_on_id":"bd-4i2.4","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-4i2.6","depends_on_id":"bd-4i2.5","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":43,"issue_id":"bd-4i2.6","author":"Harpreet Singh","text":"## Task: Implement match confidence scoring and overlap resolution\n\nThis task adds analytical nuance to raw matches: confidence levels for polysemous forms and principled resolution of overlapping spans.\n\n### Confidence levels (PLAN.md Section 4.3)\n\n- **HIGH**: Unambiguous match. The surface form maps to exactly one entity. E.g., ਅਲਾਹੁ → ALLAH (no other entity uses this form).\n- **MEDIUM**: Valid match but surface form has known polysemy (registered in polysemy.yaml). E.g., ਰਾਮ → could be RAM_DIVINE or RAM_NARRATIVE.\n- **LOW**: Match depends on context that we can't resolve in Phase 1. Flagged for Phase 3 or manual review.\n\n### Ambiguity records\nWhen confidence < HIGH, the match includes:\n```json\n\"ambiguity\": {\n  \"alternative_entities\": [\"RAM_DIVINE\", \"RAM_NARRATIVE\"],\n  \"disambiguation_rule\": null\n}\n```\nThe `disambiguation_rule` field is populated by Phase 3 if context resolves it.\n\n### Overlap resolution (PLAN.md Section 4.3)\n\nWhen two matches overlap in the same line:\n1. **Nested (one contains the other)**: Keep BOTH. Longer match is \"primary\", shorter is \"nested\". Example: SATNAM [0,9] contains NAAM [5,9] — both valid.\n2. **Partial overlap (crossing spans)**: Keep the LONGER match, discard shorter. Log at DEBUG level.\n3. **Equal-length overlap**: Keep match with higher confidence. If tied, keep both and flag for review.\n\nEach match record includes `nested_in` field: null if top-level, or the entity_id of the containing match.\n\n### Why this matters\nWithout overlap resolution, the same text could produce contradictory counts. Without confidence scoring, polysemous matches silently inflate counts for one interpretation while ignoring others. This is exactly the kind of analytical honesty the project demands.\n\n### Depends on\nbd-4i2.5 (matching engine — this task enhances its output)\nbd-4i2.4 (polysemy registry — needed to determine which forms are polysemous)\n","created_at":"2026-02-14T00:12:00Z"}]}
{"id":"bd-4i2.7","title":"Implement Phase 1 reports and aggregates generation","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-13T23:54:54.105403Z","created_by":"hsingh","updated_at":"2026-02-14T03:18:12.339124Z","closed_at":"2026-02-14T03:18:12.339109Z","close_reason":"Implemented Phase 1 reports: entity_counts.csv, entity_counts_by_ang_bucket.csv, entity_counts_by_raga.csv, and aggregates.json. Includes normalized metrics (per 1000 lines, per 10000 tokens), top entities, raga and ang-bucket distributions. 20 tests passing.","source_repo":".","compaction_level":0,"original_size":0,"labels":["phase1","reports"],"dependencies":[{"issue_id":"bd-4i2.7","depends_on_id":"bd-4i2","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-4i2.7","depends_on_id":"bd-4i2.5","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":44,"issue_id":"bd-4i2.7","author":"Harpreet Singh","text":"## Task: Implement Phase 1 reports and aggregates generation\n\nThis task produces human-readable reports and webapp-ready aggregations from match results.\n\n### Reports (PLAN.md Section 4.4)\n\nCSV reports for human analysis:\n- **entity_counts.csv**: Total count per entity across entire corpus\n- **entity_counts_by_author.csv**: Count per entity × author\n- **entity_counts_by_raga.csv**: Count per entity × raga\n- **entity_counts_by_ang_bucket.csv**: Count per entity × ang range (e.g., 1-100, 101-200)\n- **entity_counts_by_shabad.csv**: Count per entity × shabad\n\nAll counts include normalized metrics (per PLAN.md Section 4.4):\n- Per 1,000 lines\n- Per 10,000 tokens\n- Per 100 shabads\n\n### Web aggregates (aggregates.json)\nPre-computed JSON for the webapp dashboard:\n- Total entities matched\n- Top entities by frequency\n- Entity distribution by author\n- Entity distribution by raga\n- Entity distribution by ang bucket\n- Per-entity summary with total count, unique lines, unique shabads\n\n### Why normalized metrics matter\nRaw counts are misleading. Guru Nanak (M1) has far more lines than Guru Tegh Bahadur (M9). Saying \"M1 mentions ਹਰਿ more than M9\" is trivially true just from volume. Normalized metrics (per 1,000 lines of that author's text) reveal actual relative frequency.\n\n### Design: no concordance files here\nPer PLAN.md Section 8, concordance data is organized by ang range in the web bundle, NOT by entity. Entity-specific concordances are computed client-side by filtering loaded corpus chunks. This avoids the combinatorial explosion of ~1000 entity-specific files.\n\n### Depends on\nbd-4i2.5 (matching engine — provides matches.jsonl to aggregate)\n","created_at":"2026-02-14T00:12:00Z"}]}
{"id":"bd-9i3","title":"Web Bundle & Output","status":"closed","priority":2,"issue_type":"epic","created_at":"2026-02-13T23:54:23.683721Z","created_by":"hsingh","updated_at":"2026-02-14T04:01:33.631794Z","closed_at":"2026-02-14T04:01:33.631781Z","close_reason":"Web bundle & output complete - search index, reports, bundle manifest","source_repo":".","compaction_level":0,"original_size":0,"comments":[{"id":45,"issue_id":"bd-9i3","author":"Harpreet Singh","text":"## Epic: Web Bundle & Output\n\nThe web bundle is the bridge between the analysis pipeline (Python, JSONL) and the web application (React, JSON). It packages all pipeline outputs into a self-contained, CDN-ready data bundle.\n\n### Design principle: webapp consumes ONLY the bundle\nThe webapp must never reach back into raw pipeline artifacts. Everything it needs is pre-computed and packaged in data/web_bundle/. This enables:\n- Static hosting (no server needed for v1)\n- CDN distribution\n- Version-pinned snapshots\n\n### Bundle structure (PLAN.md Section 8)\n```\ndata/web_bundle/\n  manifest.json          # Stats, versions, hashes\n  aggregates.json        # Pre-computed entity counts, distributions\n  cooccurrence.json      # Co-occurrence matrix with PMI\n  corpus/\n    lines_001_100.json   # Ang 1-100 with inlined matches/features/tags\n    lines_101_200.json   # Ang 101-200\n    ...                  # ~15 chunk files total\n  search_index.json      # Pre-built client-side search index\n  lineage.json           # \"How computed\" provenance for tooltips\n```\n\n### Key innovation: ang-range chunks, not entity files\nPLAN.md Round 2 revision #11: Instead of ~1000 per-entity concordance files, corpus data is organized by ang range (~15 files). Entity-specific concordances are computed client-side by filtering the loaded chunk. This is simpler, more efficient, and avoids file explosion.\n\n### Children\n- bd-9i3.1: Bundle builder (orchestrates assembly)\n- bd-9i3.2: Ang-range corpus chunking\n- bd-9i3.3: Search index generation\n- bd-9i3.4: Manifest + lineage\n","created_at":"2026-02-14T00:11:44Z"}]}
{"id":"bd-9i3.1","title":"Implement bundle builder (web_bundle.py)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-13T23:55:12.765245Z","created_by":"hsingh","updated_at":"2026-02-14T03:49:14.098063Z","closed_at":"2026-02-14T03:49:14.098052Z","close_reason":"Implemented bundle builder: JoinedLine dataclass for pipeline data join, join_pipeline_data() joins records/matches/features/tags by line_uid, chunk_by_ang_range() splits into ang-range chunks, write_chunks() serializes to JSON, compute_aggregates() produces dashboard stats (entity freq, by-author, tag distribution, corpus stats), compute_bundle_manifest() for SHA-256 integrity hashes, validate_bundle() checks JSON validity and hash integrity, build_bundle() end-to-end orchestration. 35 tests, 640 total passing.","source_repo":".","compaction_level":0,"original_size":0,"labels":["bundle","output"],"dependencies":[{"issue_id":"bd-9i3.1","depends_on_id":"bd-2zi.3","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-9i3.1","depends_on_id":"bd-9i3","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":46,"issue_id":"bd-9i3.1","author":"Harpreet Singh","text":"## Task: Implement bundle builder (web_bundle.py)\n\nThe bundle builder orchestrates the assembly of all pipeline outputs into the web_bundle/ directory. It is the final step in the analysis pipeline.\n\n### What it does\n1. Reads all Phase outputs: ggs_lines.jsonl, matches.jsonl, features.jsonl, tags.jsonl\n2. Joins data by line_uid: for each line, attach its matches, features, and tags\n3. Delegates to sub-tasks: corpus chunking, aggregates, co-occurrence, search index, manifest, lineage\n4. Writes everything to data/web_bundle/\n5. Computes SHA256 hashes of all output files for manifest\n\n### aggregates.json generation\nPre-computes all the summary statistics the webapp dashboard needs:\n- Total corpus stats (lines, tokens, shabads, entities matched)\n- Top entities by frequency\n- Entity distribution by author, raga, ang bucket\n- Nirgun/sagun distribution summary\n- Register density summary by author\n\n### Integrity\nAfter writing the bundle, the builder validates:\n- All referenced line_uids exist in corpus chunks\n- All entity_ids in aggregates appear in the lexicon\n- All chunk files parse as valid JSON\n- Manifest hashes match actual file hashes\n\n### Depends on\nbd-2zi.3 (tag generation — bundle needs all four phases complete)\n","created_at":"2026-02-14T00:12:07Z"}]}
{"id":"bd-9i3.2","title":"Implement ang-range corpus chunking with inlined data","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-13T23:55:13.844014Z","created_by":"hsingh","updated_at":"2026-02-14T03:51:34.087111Z","closed_at":"2026-02-14T03:51:34.087099Z","close_reason":"Implemented ang-range corpus chunking with inlined data: compute_token_spans() for character-level span computation, _ang_range_key() helper, build_corpus_chunks() producing structured chunks with {ang_range, total_lines, lines} format where each line includes token_spans, write_structured_chunks() for writing structured chunk files. 16 new tests (51 total for web_bundle), 656 total passing.","source_repo":".","compaction_level":0,"original_size":0,"labels":["bundle","output"],"dependencies":[{"issue_id":"bd-9i3.2","depends_on_id":"bd-9i3","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-9i3.2","depends_on_id":"bd-9i3.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":47,"issue_id":"bd-9i3.2","author":"Harpreet Singh","text":"## Task: Implement ang-range corpus chunking with inlined data\n\nThis task creates the ~15 corpus chunk files that the webapp lazy-loads for concordance browsing.\n\n### Chunk structure (PLAN.md Section 8)\n```json\n{\n  \"ang_range\": [1, 100],\n  \"lines\": [\n    {\n      \"line_uid\": \"...\",\n      \"ang\": 1,\n      \"gurmukhi\": \"...\",\n      \"tokens\": [\"...\"],\n      \"token_spans\": [[0,3], [4,8]],\n      \"matches\": [{\"entity_id\": \"...\", \"span\": [..], ...}],\n      \"features\": {\"perso_arabic\": {\"count\": 0, \"density\": 0.0}, ...},\n      \"tags\": {\"scores\": {...}, \"primary_tag\": \"...\", ...}\n    }\n  ]\n}\n```\n\n### Chunking strategy\n- 100 angs per chunk (1-100, 101-200, ..., 1401-1430)\n- ~15 files total\n- Each chunk is self-contained: all data needed to display those angs\n- Webapp loads one chunk at a time (lazy, on-demand)\n\n### Why this approach (PLAN.md Round 2 revision #11)\nOriginal plan: per-entity concordance files (~1000+ files).\nRevised plan: per-ang-range chunks (~15 files).\n\nRationale:\n- Adding a lexicon entry doesn't create new files\n- Webapp can load one chunk and answer any query about those angs\n- Entity-specific filtering is fast client-side (just filter the loaded array)\n- Far fewer HTTP requests for the webapp\n\n### Size budget\nTarget: <20MB compressed total for all chunks. With ~60,000 lines and inline data, uncompressed may be ~100-150MB. Gzip compression should bring this well under budget.\n\n### Depends on\nbd-9i3.1 (bundle builder — chunks are generated as part of bundle assembly)\n","created_at":"2026-02-14T00:12:07Z"}]}
{"id":"bd-9i3.3","title":"Implement pre-built search index generation","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-13T23:55:14.607516Z","created_by":"hsingh","updated_at":"2026-02-14T03:39:40.390813Z","closed_at":"2026-02-14T03:39:40.390800Z","close_reason":"Implemented pre-built search index generation: SearchDocument, SearchIndex dataclasses, build_token_index/build_entity_index inverted indexes, build_search_documents from corpus records+matches, build_search_index with metadata, search_index with AND-logic multi-token query, generate_search_index batch with file output. 25 tests, 526 total passing.","source_repo":".","compaction_level":0,"original_size":0,"labels":["bundle","output"],"dependencies":[{"issue_id":"bd-9i3.3","depends_on_id":"bd-15c.8","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-9i3.3","depends_on_id":"bd-9i3","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":48,"issue_id":"bd-9i3.3","author":"Harpreet Singh","text":"## Task: Implement pre-built search index generation\n\nThis task creates a client-side search index that enables Gurmukhi text search in the webapp without a server.\n\n### Approach (PLAN.md Section 8)\n- Use MiniSearch or Lunr.js index format (pre-built at pipeline time, loaded by client)\n- Index fields: gurmukhi text, entity matches, author, raga\n- Generated from the full corpus\n- Client loads index on first search interaction (lazy — don't block initial page load)\n\n### Size budget\nTarget: <5MB compressed. The index stores tokenized terms and document pointers, not full text. Full text is in the corpus chunks.\n\n### Gurmukhi-specific considerations\n- Search must work with normalized Gurmukhi (user searches for ਹਰਿ, finds all ਹਰਿ occurrences)\n- Tokenization of search queries should match corpus tokenization\n- May need custom tokenizer plugin for the search library to handle Gurmukhi properly\n\n### Why pre-built\nBuilding a search index at runtime in the browser from 60,000 lines would be slow. Pre-building it during the pipeline run means the webapp gets instant search.\n\n### Depends on\nbd-15c.8 (Phase 0 corpus — the content being indexed)\nNote: search index only needs the corpus, not downstream analysis. It can be generated as soon as Phase 0 is done, even before Phase 1-3.\n","created_at":"2026-02-14T00:12:07Z"}]}
{"id":"bd-9i3.4","title":"Implement manifest.json and lineage.json generation","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-13T23:55:15.624279Z","created_by":"hsingh","updated_at":"2026-02-14T03:53:57.083308Z","closed_at":"2026-02-14T03:53:57.083297Z","close_reason":"Implemented manifest.json and lineage.json generation: build_bundle_manifest() for schema/version/stats/hashes/artifacts, compute_artifact_descriptors() for SHA-256 file hashing, compute_corpus_stats() and compute_lexicon_stats() for stats, build_lineage_entry() for pipeline step provenance, build_default_lineage() mapping 8 aggregate types to pipeline steps with config params, write_bundle_manifest() and write_lineage() for file output, generate_bundle_metadata() combined orchestration. 32 tests, 688 total passing.","source_repo":".","compaction_level":0,"original_size":0,"labels":["bundle","output"],"dependencies":[{"issue_id":"bd-9i3.4","depends_on_id":"bd-9i3","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-9i3.4","depends_on_id":"bd-9i3.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":49,"issue_id":"bd-9i3.4","author":"Harpreet Singh","text":"## Task: Implement manifest.json and lineage.json generation\n\nThese two files provide the provenance and transparency layer that makes the webapp trustworthy.\n\n### manifest.json (PLAN.md Section 8)\n```json\n{\n  \"schema_version\": \"1.0.0\",\n  \"generated_at\": \"2025-...\",\n  \"git_commit\": \"abc123\",\n  \"corpus_stats\": {\n    \"total_angs\": 1430,\n    \"total_lines\": 60403,\n    \"total_tokens\": 432891,\n    \"total_shabads\": 5894\n  },\n  \"lexicon_stats\": {\n    \"total_entities\": 247,\n    \"total_aliases\": 1893,\n    \"lexicon_hashes\": {\"entities\": \"sha256:...\", ...}\n  },\n  \"pipeline_versions\": {\n    \"normalizer\": \"1.2.0\",\n    \"tokenizer\": \"1.0.0\",\n    \"matcher\": \"1.1.0\",\n    \"tagger\": \"1.0.0\"\n  },\n  \"artifacts\": [\n    {\"file\": \"aggregates.json\", \"sha256\": \"...\", \"records\": 247}\n  ]\n}\n```\n\nThe manifest is the webapp's \"about this data\" page. It tells users exactly what version of everything produced the data they're looking at.\n\n### lineage.json (PLAN.md Section 8)\nMaps each aggregate/chart to the exact pipeline step, config parameters, and lexicon files that produced it. Consumed by the webapp's \"How computed\" tooltips.\n\nExample:\n```json\n{\n  \"entity_counts_by_author\": {\n    \"produced_by\": \"Phase 1: Lexical Analysis\",\n    \"inputs\": [\"ggs_lines.jsonl\", \"lexicon/entities.yaml\"],\n    \"config_params\": {\"normalization.nukta_policy\": \"PRESERVE\"},\n    \"description\": \"Count of entity matches per author, normalized per 1,000 lines\"\n  }\n}\n```\n\n### Why lineage matters\nThis is the \"trust-by-design\" principle (PLAN_WEBAPP.md Section 4). Every chart in the webapp should be auditable: \"this number comes from this pipeline step using these inputs with these settings.\" No opaque black-box logic.\n\n### Depends on\nbd-9i3.1 (bundle builder — manifest/lineage are generated during bundle assembly)\n","created_at":"2026-02-14T00:12:07Z"}]}
{"id":"bd-9qw","title":"Phase 2: Structural Analysis","status":"closed","priority":1,"issue_type":"epic","created_at":"2026-02-13T23:54:22.548361Z","created_by":"hsingh","updated_at":"2026-02-14T04:01:33.527987Z","closed_at":"2026-02-14T04:01:33.527976Z","close_reason":"Phase 2 structural analysis complete - co-occurrence, density, stats, cross-tradition","source_repo":".","compaction_level":0,"original_size":0,"comments":[{"id":50,"issue_id":"bd-9qw","author":"Harpreet Singh","text":"## Epic: Phase 2 — Structural Analysis\n\nPhase 2 builds on Phase 1's match results to compute structural features: register density, co-occurrence patterns, and statistical measures. This phase answers questions like \"how Perso-Arabic is this raga?\" and \"which entities appear together most often?\"\n\n### Key insight: Phase 2 does NOT re-run matching\nPhase 2 consumes `matches.jsonl` from Phase 1 and classifies matches by register using lexicon metadata. It never touches the raw corpus directly for matching. This separation ensures that changing analytical methods (Phase 2) doesn't require re-running matching (Phase 1).\n\n### Outputs\n- `data/derived/features.jsonl` — per-line feature vectors with continuous density scores\n- `data/web_bundle/cooccurrence.json` — entity co-occurrence matrix with PMI scores\n\n### Children (execution flow)\n- bd-9qw.1: Feature computation (needs Phase 1 matches)\n- bd-9qw.2: Co-occurrence engine (needs Phase 1 matches, parallel with features)\n- bd-9qw.3: PMI stability (needs co-occurrence)\n- bd-9qw.4: Register density aggregations (needs features)\n- bd-9qw.5: Statistical guardrails (needs features)\n- bd-9qw.6: Cross-tradition analysis (needs co-occurrence + PMI)\n\n### Note: features and co-occurrence are independent\nFeature computation and co-occurrence are both downstream of Phase 1 matches but independent of each other. They can be developed and run in parallel.\n","created_at":"2026-02-14T00:11:44Z"}]}
{"id":"bd-9qw.1","title":"Implement per-line feature computation (features.py)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:54:57.338866Z","created_by":"hsingh","updated_at":"2026-02-14T01:36:07.950839Z","closed_at":"2026-02-14T01:36:07.950827Z","close_reason":"Implemented per-line feature computation (features.py). 6 feature dimensions: perso_arabic, sanskritic, nirgun, sagun_narrative, ritual, cleric. Each feature has count, density (continuous 0-1), and matched_tokens. Entity->dimension classification based on register and category metadata. Skips nested matches to avoid double-counting. compute_corpus_features() batch API with JSONL output.","source_repo":".","compaction_level":0,"original_size":0,"labels":["analysis","phase2"],"dependencies":[{"issue_id":"bd-9qw.1","depends_on_id":"bd-4i2.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-9qw.1","depends_on_id":"bd-4i2.5","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-9qw.1","depends_on_id":"bd-9qw","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":51,"issue_id":"bd-9qw.1","author":"Harpreet Singh","text":"## Task: Implement per-line feature computation (features.py)\n\nThis task computes continuous density scores for each line, capturing the register profile of every line in the corpus.\n\n### Feature vector (PLAN.md Section 5)\n\nFor each line, compute:\n- **perso_arabic_density**: count of Perso-Arabic register matches / total_tokens\n- **sanskritic_density**: count of Sanskritic register matches / total_tokens\n- **nirgun_density**: count of nirgun entity matches / total_tokens\n- **sagun_narrative_density**: count of sagun narrative matches / total_tokens\n- **ritual_density**: count of ritual/practice matches / total_tokens\n- **cleric_density**: count of cleric-related matches / total_tokens\n\nEach feature includes: count, density (0.0-1.0), and matched_tokens list.\n\n### Feature record schema (PLAN.md Section 5)\n```json\n{\n  \"line_uid\": \"...\",\n  \"shabad_uid\": \"...\",\n  \"token_count\": 18,\n  \"features\": {\n    \"perso_arabic\": {\"count\": 3, \"density\": 0.167, \"matched_tokens\": [\"ਅਲਾਹ\", \"...\"]},\n    \"sanskritic\":   {\"count\": 0, \"density\": 0.0,   \"matched_tokens\": []},\n    ...\n  }\n}\n```\n\n### Why continuous density, not boolean\nPLAN.md explicitly chose continuous density over boolean flags (Round 1 revision #5). A line with 3 Perso-Arabic terms out of 18 tokens (density 0.167) carries more signal than a boolean \"has_perso_arabic=true\". Density enables:\n- Meaningful averages across shabads, ragas, authors\n- Gradient analysis (how MUCH of register X, not just whether it's present)\n- More informative visualizations (heatmaps, not just presence/absence)\n\nBoolean convenience fields are derived as `density > 0` for backward compatibility.\n\n### Implementation\n1. Load matches.jsonl (from Phase 1)\n2. Load lexicon metadata (entity → register mapping)\n3. For each line: count matches by register category, divide by token_count\n4. Write features.jsonl\n\n### Parallelism\nCan be parallelized by ang (each ang's lines computed independently).\n\n### Depends on\nbd-4i2.5 (matching engine — provides matches.jsonl)\nbd-4i2.1 (lexicon loader — provides entity → register mapping)\n","created_at":"2026-02-14T00:12:02Z"}]}
{"id":"bd-9qw.2","title":"Implement co-occurrence engine (line-level and shabad-level)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:54:58.329080Z","created_by":"hsingh","updated_at":"2026-02-14T03:06:02.681022Z","closed_at":"2026-02-14T03:06:02.681011Z","close_reason":"Implemented co-occurrence engine with line-level and shabad-level window analysis. Computes raw_count, PMI, normalized PMI, and Jaccard similarity for entity pairs. 45 tests passing.","source_repo":".","compaction_level":0,"original_size":0,"labels":["analysis","phase2"],"dependencies":[{"issue_id":"bd-9qw.2","depends_on_id":"bd-4i2.5","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-9qw.2","depends_on_id":"bd-9qw","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":52,"issue_id":"bd-9qw.2","author":"Harpreet Singh","text":"## Task: Implement co-occurrence engine (line-level and shabad-level)\n\nCo-occurrence captures which entities appear together. This is one of the most analytically interesting outputs — it reveals thematic associations in the GGS text.\n\n### Definition (PLAN.md Section 5.1)\nTwo entities co-occur when they appear in the same WINDOW.\n\n### Window levels (both computed)\n- **LINE**: Same line. Tightest, most conservative. Best for entities in direct syntactic relationship.\n- **SHABAD**: Same shabad (hymn/composition). Captures thematic co-occurrence. A shabad that mentions both ਅਲਾਹ and ਰਾਮ in different lines reveals thematic juxtaposition.\n\n### Pair computation\nFor each window:\n1. Collect set of unique entity_ids that matched within it\n2. For each pair (A, B) where A < B (alphabetical — avoids double counting):\n   - Increment raw co-occurrence count\n\n### Metrics per pair\n- **raw_count**: Windows containing both A and B\n- **pmi**: log2(P(A,B) / (P(A) * P(B))) — measures association strength\n- **normalized_pmi**: pmi / -log2(P(A,B)) — bounded [-1, 1]\n- **jaccard**: |windows with both| / |windows with either| — similarity measure\n\n### Output\nSparse matrix: only pairs with raw_count >= 2 are stored.\nWritten to `data/web_bundle/cooccurrence.json`.\n\n### Why this matters for the GGS\nThe GGS frequently juxtaposes concepts from different traditions. Co-occurrence analysis can quantitatively surface patterns like:\n- Ram + Allah appearing together (universalist passages)\n- Ritual terms + negation words (critique-of-ritual pattern)\n- Nirgun concepts + Perso-Arabic vocabulary (cross-register blending)\n\n### Depends on\nbd-4i2.5 (matching engine — provides matches.jsonl to analyze)\n","created_at":"2026-02-14T00:12:02Z"}]}
{"id":"bd-9qw.3","title":"Implement PMI stability measures (smoothing, min-freq, min-support)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:54:59.515887Z","created_by":"hsingh","updated_at":"2026-02-14T03:26:25.385713Z","closed_at":"2026-02-14T03:26:25.385699Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["analysis","phase2"],"dependencies":[{"issue_id":"bd-9qw.3","depends_on_id":"bd-9qw","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-9qw.3","depends_on_id":"bd-9qw.2","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":53,"issue_id":"bd-9qw.3","author":"Harpreet Singh","text":"## Task: Implement PMI stability measures (smoothing, min-freq, min-support)\n\nRaw PMI (Pointwise Mutual Information) is notoriously unstable for rare events. This task adds the statistical safeguards that make PMI results trustworthy.\n\n### The problem with raw PMI\nPMI = log2(P(A,B) / (P(A) * P(B)))\n\nIf entity A appears only twice in the entire corpus and both times with entity B, the raw PMI is extremely high — but this is just noise from small sample size, not a meaningful association. Without corrections, rare entities dominate the co-occurrence rankings with spurious results.\n\n### Three stability measures (PLAN.md Section 5.1)\n\n1. **Minimum entity frequency** (default: 10)\n   - Entities appearing fewer than `min_entity_freq` times are excluded from co-occurrence entirely\n   - Prevents rare entities from producing extreme PMI values\n   - 10 is a reasonable threshold for a 60,000-line corpus\n\n2. **Laplace smoothing** (default k=1)\n   - Add-k smoothing applied to all frequency counts before PMI computation\n   - `smoothed_pmi = log2((count(A,B) + k) * N / ((count(A) + k*V) * (count(B) + k*V)))`\n   - Where V = unique entities, N = total windows\n   - Prevents log(0) and dampens extreme values for rare pairs\n\n3. **Minimum co-occurrence for PMI reporting** (default: 5)\n   - Pairs with raw_count >= 2 are stored (with raw_count and jaccard)\n   - PMI is only computed and reported for pairs with raw_count >= 5\n   - Pairs with 2-4 co-occurrences get PMI = null (insufficient evidence)\n\n### Config\n```yaml\ncooccurrence:\n  min_entity_freq: 10\n  smoothing_k: 1\n  min_pmi_support: 5\n```\n\n### Why this matters\nWithout these measures, the co-occurrence output would be dominated by noise from rare entities. The stability measures ensure that reported associations are statistically meaningful. This is the \"statistical claims include uncertainty\" design principle in action.\n\n### Depends on\nbd-9qw.2 (co-occurrence engine — this task adds safeguards to its output)\n","created_at":"2026-02-14T00:12:02Z"}]}
{"id":"bd-9qw.4","title":"Implement register density aggregations and sliding window","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-13T23:55:00.351794Z","created_by":"hsingh","updated_at":"2026-02-14T03:14:19.209189Z","closed_at":"2026-02-14T03:14:19.209174Z","close_reason":"Implemented register density aggregations: per-ang mean density, per-raga stats (mean/median/stdev), and sliding window analysis with configurable window size. Loads raga sections from ragas.yaml. 32 tests passing.","source_repo":".","compaction_level":0,"original_size":0,"labels":["analysis","phase2"],"dependencies":[{"issue_id":"bd-9qw.4","depends_on_id":"bd-9qw","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-9qw.4","depends_on_id":"bd-9qw.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":54,"issue_id":"bd-9qw.4","author":"Harpreet Singh","text":"## Task: Implement register density aggregations and sliding window\n\nThis task aggregates per-line density scores into higher-level views: by author, by raga, by ang progression, and through a sliding window for visualizing register shifts.\n\n### Aggregations (PLAN.md Section 5.2)\n\nFor each register (Sanskritic, Perso-Arabic):\n- **By author**: Mean, median, std of density across all lines by each author. Answers: \"How Sanskritic is Guru Nanak's language compared to Kabir's?\"\n- **By raga**: Same aggregation conditioned by raga. Answers: \"Which ragas have the highest Perso-Arabic density?\"\n- **By ang progression**: Density averaged per ang or ang bucket. Shows how register usage varies across the physical ordering of the text.\n\n### Sliding window analysis\n- Window of W angs (default 20, configurable)\n- Compute rolling mean density per register\n- Produces a time-series-like view of register shifts across 1430 angs\n- Enables visualizations showing where the text shifts between registers\n\n### Key analytical value\nThis directly supports one of the project's most compelling outputs: a heatmap or line chart showing how Perso-Arabic vs. Sanskritic register ebbs and flows across the GGS. This has never been done quantitatively before at the level of the entire text.\n\n### Output\nResults are written as part of features aggregation. The sliding window data goes into the web bundle for visualization.\n\n### Depends on\nbd-9qw.1 (feature computation — provides per-line density scores to aggregate)\n","created_at":"2026-02-14T00:12:02Z"}]}
{"id":"bd-9qw.5","title":"Implement statistical guardrails (stats.py)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-13T23:55:01.199775Z","created_by":"hsingh","updated_at":"2026-02-14T03:16:10.836560Z","closed_at":"2026-02-14T03:16:10.836546Z","close_reason":"Implemented statistical guardrails in stats.py: log-odds ratio with smoothing prior, bootstrap confidence intervals (percentile method), minimum support threshold, and Cohen's d effect size with qualitative interpretation. 31 tests passing.","source_repo":".","compaction_level":0,"original_size":0,"labels":["analysis","phase2"],"dependencies":[{"issue_id":"bd-9qw.5","depends_on_id":"bd-9qw","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-9qw.5","depends_on_id":"bd-9qw.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":55,"issue_id":"bd-9qw.5","author":"Harpreet Singh","text":"## Task: Implement statistical guardrails (stats.py)\n\nThis task adds rigorous statistical controls to prevent over-interpretation of feature data. The project demands that \"statistical claims include uncertainty.\"\n\n### Measures (PLAN.md Section 5.3)\n\n1. **Log-odds ratio with smoothing prior**\n   - Compares entity frequency in one group (e.g., author M1) vs. background rate\n   - Smoothing prior prevents infinite log-odds for entities unique to one author\n   - More robust than simple ratios for comparing groups of different sizes\n\n2. **Bootstrap confidence intervals**\n   - Non-parametric CI for density estimates\n   - Sample lines with replacement, recompute density, repeat 1000x\n   - Report 95% CI for each density estimate\n   - Wide CI = \"we're not confident in this number\"\n\n3. **Minimum support threshold** (default: 20)\n   - Density estimates based on fewer than 20 observations are flagged as \"low support\"\n   - Prevents reporting precise-looking numbers for tiny sample sizes\n\n4. **Effect size ranking**\n   - Rank differences by effect size (e.g., Cohen's d), not just statistical significance\n   - A 0.001 density difference might be \"significant\" with 60,000 lines but is analytically meaningless\n   - Focus on \"how different\" not just \"is it different\"\n\n### Philosophy: \"descriptive distinctiveness\"\nAll outputs are explicitly labeled as \"descriptive distinctiveness\" — never causal claims. Saying \"M1 uses more Perso-Arabic vocabulary than M5\" is descriptive. Saying \"M1 was more influenced by Islamic tradition\" is interpretive and beyond our scope.\n\n### Depends on\nbd-9qw.1 (feature computation — provides the density scores to put guardrails on)\n","created_at":"2026-02-14T00:12:02Z"}]}
{"id":"bd-9qw.6","title":"Implement cross-tradition and ritual-negation analysis","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-13T23:55:02.285960Z","created_by":"hsingh","updated_at":"2026-02-14T03:31:55.908936Z","closed_at":"2026-02-14T03:31:55.908924Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["analysis","phase2"],"dependencies":[{"issue_id":"bd-9qw.6","depends_on_id":"bd-9qw","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-9qw.6","depends_on_id":"bd-9qw.2","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-9qw.6","depends_on_id":"bd-9qw.3","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":56,"issue_id":"bd-9qw.6","author":"Harpreet Singh","text":"## Task: Implement cross-tradition and ritual-negation analysis\n\nThis task targets two of the most analytically distinctive patterns in the GGS: cross-tradition entity pairing and the critique-of-ritual pattern.\n\n### Cross-tradition pairing (PLAN.md Section 5.1)\nFilter co-occurrence pairs where A.tradition != B.tradition, ranked by normalized PMI.\nExamples:\n- (ALLAH, RAM) — Islamic + Vaishnava traditions co-occurring\n- (KHUDA, BRAHM) — Perso-Arabic + Sanskritic divine names together\n\nThis surfaces the GGS's most distinctive literary feature: its systematic juxtaposition of vocabulary from different devotional traditions, used to express universalist theology.\n\n### Ritual + negation patterns (PLAN.md Section 5.1)\nSpecial co-occurrence analysis: ritual markers + negation tokens in the same line.\n- Uses a small negation lexicon: ਨਾ, ਨਾਹੀ, ਬਿਨੁ, ਬਾਝੁ, etc.\n- Captures the GGS's recurring critique-of-ritual pattern quantitatively\n- Example: \"ਤੀਰਥਿ ਨਾਵਣ ਜਾਉ ਤੀਰਥੁ ਨਾਮੁ ਹੈ\" — ritual term + negation in context of pilgrimage\n\n### Why these are separated from general co-occurrence\nThese analyses apply domain-specific filters (tradition mismatch, ritual+negation) that produce curated, high-signal results. General co-occurrence produces a raw matrix; these tasks interpret it through the lens of GGS-specific scholarly questions.\n\n### Analytical significance\nThe cross-tradition pairing analysis is arguably the single most compelling analytical output of this project. No other quantitative analysis of the GGS has systematically measured how different religious vocabularies co-occur and in what patterns.\n\n### Depends on\nbd-9qw.2 (co-occurrence engine — provides the raw co-occurrence matrix)\nbd-9qw.3 (PMI stability — ensures PMI values are trustworthy)\n","created_at":"2026-02-14T00:12:02Z"}]}
{"id":"bd-tun","title":"Pipeline Infrastructure","status":"closed","priority":1,"issue_type":"epic","created_at":"2026-02-13T23:54:24.974384Z","created_by":"hsingh","updated_at":"2026-02-14T04:01:33.581211Z","closed_at":"2026-02-14T04:01:33.581199Z","close_reason":"Pipeline infra complete - caching, parallel execution","source_repo":".","compaction_level":0,"original_size":0,"comments":[{"id":57,"issue_id":"bd-tun","author":"Harpreet Singh","text":"## Epic: Pipeline Infrastructure\n\nThis epic covers cross-cutting concerns that all phases share: error handling, caching, provenance tracking, and parallelism. These aren't features — they're the plumbing that makes the pipeline robust.\n\n### Why a separate epic\nError handling and caching are used by every phase but belong to no single phase. Implementing them as shared infrastructure prevents code duplication and ensures consistent behavior.\n\n### Children\n- bd-tun.1: Error model (FATAL/ERROR/WARNING classification)\n- bd-tun.2: Incremental caching (skip unchanged phases)\n- bd-tun.3: Run manifest generation (provenance tracking)\n- bd-tun.4: Parallel execution framework (ProcessPoolExecutor)\n\n### Execution order\nError model and manifest are independent and can be done in parallel. Caching depends on manifest (needs hash computation). Parallelism depends on error model (workers must handle errors consistently).\n","created_at":"2026-02-14T00:11:44Z"}]}
{"id":"bd-tun.1","title":"Implement pipeline error model (FATAL/ERROR/WARNING)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:55:30.294053Z","created_by":"hsingh","updated_at":"2026-02-14T01:06:28.769826Z","closed_at":"2026-02-14T01:06:28.769813Z","close_reason":"Implemented pipeline error model: Severity enum (FATAL/ERROR/WARNING), PipelineError/FatalPipelineError exception hierarchy, ErrorRecord dataclass for JSONL output, ErrorConfig from config.yaml, ErrorCollector with threshold-based abort and strict_mode escalation. Uses rich console for colored error output.","source_repo":".","compaction_level":0,"original_size":0,"labels":["infra","pipeline"],"dependencies":[{"issue_id":"bd-tun.1","depends_on_id":"bd-298.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-tun.1","depends_on_id":"bd-tun","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":58,"issue_id":"bd-tun.1","author":"Harpreet Singh","text":"## Task: Implement pipeline error model (FATAL/ERROR/WARNING)\n\nThis task establishes the uniform error handling contract that all phases follow. Without it, each phase would handle errors differently, making the pipeline unpredictable.\n\n### Error severity levels (PLAN.md Section 2.1)\n\n**FATAL** — Pipeline cannot continue. Abort immediately.\n- Missing input file (e.g., ggs_lines.jsonl not found)\n- Schema validation failure (input doesn't match expected schema)\n- Corpus integrity violation (duplicate line_uids)\n- Action: Exit non-zero, print actionable error message\n\n**ERROR** — Single record cannot be processed. Skip record, continue pipeline.\n- Malformed lexicon entry\n- Unparseable line\n- Division by zero in density computation\n- Action: Write to `<phase>_errors.jsonl`, continue processing\n\n**WARNING** — Record processed but with degraded quality. Continue.\n- Token count unusually high (>100)\n- Match confidence LOW\n- Shabad boundary ambiguous\n- Action: Record in run_manifest.json summary\n\n### Error record schema\n```json\n{\n  \"line_uid\": \"...\",\n  \"phase\": \"lexical\",\n  \"severity\": \"ERROR\",\n  \"error_type\": \"DIVISION_BY_ZERO\",\n  \"message\": \"Token count is 0 after structural marker removal\",\n  \"context\": {\"ang\": 433, \"line_id\": \"433:07\"}\n}\n```\n\n### Pipeline completion rules\n- FATAL: abort, exit non-zero\n- ERROR count > threshold (default 100): abort (likely systematic issue)\n- Warnings: always continue\n\n### Config\n```yaml\nerror_handling:\n  max_record_errors: 100\n  strict_mode: false  # if true, treat WARNINGs as ERRORs\n```\n\n### Implementation\nA shared module (e.g., `src/ggs/errors.py`) providing:\n- `PipelineError` exception hierarchy\n- Error collector that accumulates errors and writes to JSONL\n- Warning counter for manifest summary\n- Threshold-based abort logic\n\n### Depends on\nbd-298.1 (package structure)\n","created_at":"2026-02-14T00:12:14Z"}]}
{"id":"bd-tun.2","title":"Implement incremental caching (.cache/ with input hashing)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-13T23:55:31.362716Z","created_by":"hsingh","updated_at":"2026-02-14T03:34:05.752895Z","closed_at":"2026-02-14T03:34:05.752882Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["infra","pipeline"],"dependencies":[{"issue_id":"bd-tun.2","depends_on_id":"bd-tun","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-tun.2","depends_on_id":"bd-tun.3","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":59,"issue_id":"bd-tun.2","author":"Harpreet Singh","text":"## Task: Implement incremental caching (.cache/ with input hashing)\n\nIncremental caching prevents re-running expensive phases when inputs haven't changed. This saves significant time during development iteration.\n\n### Mechanism (PLAN.md Section 2)\n\n1. Before each phase runs, compute hash of ALL inputs:\n   - Corpus file hash (SHA256 of ggs_lines.jsonl)\n   - Lexicon hashes (SHA256 of each lexicon file)\n   - Config hash (SHA256 of config.yaml)\n   - Code version hash (git commit or module version)\n\n2. Compare computed hash against cached value in `.cache/<phase>_input_hash.json`\n\n3. If hashes match AND output artifacts exist → skip phase entirely\n\n4. If hashes differ → run phase, update cache file\n\n5. `--force` flag bypasses cache\n\n### Cache location\n`.cache/` at project root (not inside `data/`). This is explicitly separate from data artifacts:\n- `.cache/` is gitignored, ephemeral, can be deleted without losing anything\n- `data/` artifacts have provenance and are published\n\n### Cache file schema\n```json\n{\n  \"phase\": \"lexical\",\n  \"computed_at\": \"2025-...\",\n  \"input_hashes\": {\n    \"corpus\": \"sha256:abc...\",\n    \"lexicon/entities.yaml\": \"sha256:def...\",\n    \"config.yaml\": \"sha256:ghi...\"\n  },\n  \"output_hashes\": {\n    \"matches.jsonl\": \"sha256:xyz...\"\n  }\n}\n```\n\n### Priority: P2\nNice optimization but not blocking. The pipeline works fine without caching (just slower during development). More important to get core functionality right first.\n\n### Depends on\nbd-tun.3 (manifest generation — caching reuses hash computation from manifest logic)\n","created_at":"2026-02-14T00:12:14Z"}]}
{"id":"bd-tun.3","title":"Implement run_manifest.json generation","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-13T23:55:32.319211Z","created_by":"hsingh","updated_at":"2026-02-14T01:11:13.863318Z","closed_at":"2026-02-14T01:11:13.863305Z","close_reason":"Implemented run_manifest.json generation: RunManifest builder with record_input/output/lexicon for SHA-256 hashing, set_record_counts and set_error_summary for metadata, finalize() writes JSON. Includes file_sha256, dir_sha256, and git commit detection utilities.","source_repo":".","compaction_level":0,"original_size":0,"labels":["infra","pipeline"],"dependencies":[{"issue_id":"bd-tun.3","depends_on_id":"bd-298.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-tun.3","depends_on_id":"bd-tun","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":60,"issue_id":"bd-tun.3","author":"Harpreet Singh","text":"## Task: Implement run_manifest.json generation\n\nThe run manifest is the provenance anchor for every pipeline run. It records exactly what was run, with what inputs, producing what outputs.\n\n### Manifest schema (PLAN.md Section 2)\n\n```json\n{\n  \"schema_version\": \"1.0.0\",\n  \"phase\": \"lexical\",\n  \"generator_version\": \"0.1.0\",\n  \"generated_at\": \"2025-02-13T...\",\n  \"git_commit\": \"abc123\",\n  \"wall_clock_seconds\": 42.5,\n  \"input_manifest_hash\": \"sha256:...\",\n  \"config_hash\": \"sha256:...\",\n  \"lexicon_hashes\": {\n    \"entities.yaml\": \"sha256:...\",\n    \"nirgun.yaml\": \"sha256:...\"\n  },\n  \"output_artifact_hashes\": {\n    \"matches.jsonl\": \"sha256:...\",\n    \"entity_counts.csv\": \"sha256:...\"\n  },\n  \"record_counts\": {\n    \"total_input_lines\": 60403,\n    \"total_matches\": 128392,\n    \"errors\": 0,\n    \"warnings\": 14\n  },\n  \"error_summary\": {\n    \"warning_types\": {\"HIGH_TOKEN_COUNT\": 14}\n  }\n}\n```\n\n### What it enables\n1. **Reproducibility**: Anyone can check what code version + config produced a given output\n2. **Integrity verification**: Output hashes let you verify files haven't been modified\n3. **Debugging**: wall_clock_seconds and record_counts help identify performance regressions\n4. **Caching**: Input hashes are reused by the caching system (bd-tun.2)\n\n### Implementation\nA utility module providing:\n- `start_manifest(phase, config)` — begins tracking\n- `record_input(path)` — compute and store input hash\n- `record_output(path)` — compute and store output hash\n- `finalize_manifest()` — write run_manifest.json\n\n### Depends on\nbd-298.1 (package structure)\n","created_at":"2026-02-14T00:12:14Z"}]}
{"id":"bd-tun.4","title":"Implement parallel execution framework (ProcessPoolExecutor)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-13T23:55:33.207069Z","created_by":"hsingh","updated_at":"2026-02-14T03:35:59.749035Z","closed_at":"2026-02-14T03:35:59.749023Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["infra","pipeline"],"dependencies":[{"issue_id":"bd-tun.4","depends_on_id":"bd-tun","type":"parent-child","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""},{"issue_id":"bd-tun.4","depends_on_id":"bd-tun.1","type":"blocks","created_at":"2026-02-14T00:16:34Z","created_by":"import","metadata":"{}","thread_id":""}],"comments":[{"id":61,"issue_id":"bd-tun.4","author":"Harpreet Singh","text":"## Task: Implement parallel execution framework (ProcessPoolExecutor)\n\nThis task adds parallelism to computationally intensive phases, reducing wall-clock time on multi-core machines.\n\n### Parallelism strategy (PLAN.md Section 9)\n\n- **Phase 0**: Sequential (rate-limited HTTP — parallelism would violate scraping protocol)\n- **Phase 1**: Parallel by ang (each ang's lines processed independently)\n- **Phase 2**: Parallel by ang (features computed per-line, no cross-line dependency)\n- **Phase 3**: Parallel by shabad (tagging uses shabad-level context, so shabad is the partition unit)\n- **Bundle**: Sequential (aggregation step, fast enough)\n\n### Implementation: concurrent.futures.ProcessPoolExecutor\n\n```python\ndef run_parallel(func, partitions, workers=None):\n    workers = workers or os.cpu_count()\n    with ProcessPoolExecutor(max_workers=workers) as pool:\n        futures = {pool.submit(func, partition): key for key, partition in partitions.items()}\n        results = {}\n        for future in as_completed(futures):\n            key = futures[future]\n            results[key] = future.result()  # propagates exceptions\n    return results\n```\n\n### Deterministic output regardless of worker count\nResults from all workers are merged and sorted by line_uid before writing. This ensures that the output is byte-identical regardless of how many workers ran or in what order they completed. This is critical for the reproducibility property verified by roundtrip tests (bd-3jj.9).\n\n### Error handling in workers\nEach worker uses the pipeline error model (bd-tun.1). Errors are collected per-worker and merged after all workers complete. If any worker hits a FATAL error, the entire phase aborts.\n\n### --workers N flag\nConfigurable via CLI (or config). Default: cpu_count(). Set to 1 for debugging (easier stack traces).\n\n### Priority: P2\nThe pipeline works single-threaded. Parallelism is a performance optimization. Get correctness first, then speed.\n\n### Depends on\nbd-tun.1 (error model — workers must handle errors consistently)\n","created_at":"2026-02-14T00:12:14Z"}]}
